{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts here are used for tokenization and preparing the train/dev/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are titles, punctuations, and contractions that need to be replaced.\n",
    "\n",
    "replacing_titles = ['Dr.','Esq.','Hon.','Jr.','Mr.','Mrs.','Ms.','Messrs.','Mmes.','Msgr.','Prof.','Rev.','Rt. Hon.','Sr.','St.']\n",
    "punctuation_marks = ['\"', \"'\", \"!\", \"@\", \"#\", \"$\", \"%\", \"&\", \"*\", \"(\", \")\", \"-\", \"?\", \",\", \".\"]\n",
    "contractions_dict = {\"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he had\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I had\",\"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"iit will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she had\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that had\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they had\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\"you're\": \"you are\",\"you've\": \"you have\"}\n",
    "country_acronyms = {\"U.S\": \"United States\", \"U.S.A\": \"United States of America\", \"U.A.E\": \"United Arab Emirates\", \"U.S.S.R\": \"Union of Soviet Socialist Republics\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input_file):\n",
    "    \"\"\"\n",
    "    This function accomplishes four purposes:\n",
    "    1. Remove the title and date (the first two rows) from the input file\n",
    "    2. Remove all special characters except for . and ,\n",
    "    3. Convert all characters to lower case\n",
    "    4. Tokenize words\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): input file\n",
    "        \n",
    "    Returns:\n",
    "        output_file (str): tokenized strings separated by space\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    input_file = open(input_file, 'r').read()\n",
    "    \n",
    "    # Remove the title and date (the first two rows)\n",
    "    \n",
    "    startChar = [word.end() for word in re.finditer(\"\\n\", input_file)][1]\n",
    "    input2 = input_file[startChar:]\n",
    "    \n",
    "    # Remove things in angle quotes which are added to account for crowd reactions\n",
    "    input2 = re.sub(r\"\\<[^\\>]*\\>\", '', input2)\n",
    "    \n",
    "    # lowercase everything so that we have less tokens to predict. i.e., no need to distinguish a vs. A\n",
    "    #input2 = input2.lower()\n",
    "    \n",
    "    # Standardize contractions\n",
    "    for k, v in contractions_dict.items():\n",
    "        input2 = input2.replace(k, v) \n",
    "        \n",
    "        k_caps = k[:1].upper() + k[1:]\n",
    "        v_caps = v[:1].upper() + v[1:]\n",
    "        \n",
    "        input2 = input2.replace(k_caps, v_caps)\n",
    "        \n",
    "    # Replace country acronyms\n",
    "    for k, v in country_acronyms.items():\n",
    "        input2 = input2.replace(k, v)\n",
    "        \n",
    "    # Remove middle initial\n",
    "    input2 = re.sub(r\"([A-Z])\\W \", '', input2)\n",
    "    \n",
    "    # Keep all the words and digitis\n",
    "    # Keep only two special characters: . and ,\n",
    "    # If we want to keep carriage return, add |\\n\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|[\\.\\,]')\n",
    "    tokens = tokenizer.tokenize(input2)\n",
    "    output_file = \" \".join(tokens)\n",
    "    output_file = output_file + \"<speech_sep>\"\n",
    "    \n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "['obama_speeches_028.txt' 'obama_speeches_015.txt'\n",
      " 'obama_speeches_018.txt' 'obama_speeches_045.txt'\n",
      " 'obama_speeches_035.txt' 'obama_speeches_000.txt'\n",
      " 'obama_speeches_041.txt' 'obama_speeches_039.txt'\n",
      " 'obama_speeches_019.txt' 'obama_speeches_001.txt'\n",
      " 'obama_speeches_003.txt' 'obama_speeches_032.txt'\n",
      " 'obama_speeches_040.txt' 'obama_speeches_029.txt'\n",
      " 'obama_speeches_002.txt' 'obama_speeches_014.txt'\n",
      " 'obama_speeches_005.txt' 'obama_speeches_033.txt'\n",
      " 'obama_speeches_016.txt']\n",
      "Validation set:\n",
      "['obama_speeches_017.txt' 'obama_speeches_021.txt'\n",
      " 'obama_speeches_048.txt' 'obama_speeches_007.txt'\n",
      " 'obama_speeches_046.txt' 'obama_speeches_012.txt'\n",
      " 'obama_speeches_013.txt' 'obama_speeches_049.txt'\n",
      " 'obama_speeches_010.txt' 'obama_speeches_044.txt'\n",
      " 'obama_speeches_009.txt' 'obama_speeches_022.txt'\n",
      " 'obama_speeches_047.txt' 'obama_speeches_004.txt'\n",
      " 'obama_speeches_037.txt' 'obama_speeches_020.txt'\n",
      " 'obama_speeches_042.txt']\n",
      "Test set:\n",
      "['obama_speeches_034.txt' 'obama_speeches_011.txt'\n",
      " 'obama_speeches_038.txt' 'obama_speeches_043.txt'\n",
      " 'obama_speeches_006.txt' 'obama_speeches_026.txt'\n",
      " 'obama_speeches_031.txt' 'obama_speeches_008.txt'\n",
      " 'obama_speeches_030.txt' 'obama_speeches_023.txt'\n",
      " 'obama_speeches_036.txt' 'obama_speeches_027.txt']\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Select a president to build models on\n",
    "pres = ['obama']\n",
    "\n",
    "# split_pct = [training_pct, validation_pct, test_pct]\n",
    "split_pct = [.4, .4, .3]\n",
    "\n",
    "# Set sed number\n",
    "np.random.seed(266)\n",
    "\n",
    "# Get current directory\n",
    "cwd = getcwd()\n",
    "\n",
    "for pre in pres:\n",
    "    \n",
    "    dir_output = f\"1.DataPreparationResults/{pre}\"\n",
    "    \n",
    "    if not os.path.exists(dir_output):\n",
    "        os.makedirs(dir_output)\n",
    "    \n",
    "    out_train = open(f\"{dir_output}/train.txt\",\"w+\")\n",
    "    out_val = open(f\"{dir_output}/val.txt\",\"w+\")\n",
    "    out_test = open(f\"{dir_output}/test.txt\",\"w+\")\n",
    "    dir_president = f\"CorpusOfPresidentialSpeeches/{pre}\"\n",
    "    \n",
    "    # onlyfiles contains a list of files (not directories) under path_president\n",
    "    # Reference: https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "    onlyfiles_lst = [f for f in listdir(dir_president) if isfile(join(dir_president, f))]\n",
    "    num_of_files = len(onlyfiles_lst)\n",
    "\n",
    "    # Reference: https://stackoverflow.com/questions/15511349/select-50-items-from-list-at-random-to-write-to-file/39585770\n",
    "    files_train_arr = np.random.choice(onlyfiles_lst, round(num_of_files*split_pct[0]), replace=False)\n",
    "\n",
    "    # Set substraction: https://stackoverflow.com/questions/3428536/python-list-subtraction-operation\n",
    "    files_val_test_lst = list(set(onlyfiles_lst) - set(files_train_arr))\n",
    "    files_val_arr = np.random.choice(files_val_test_lst, round(len(files_val_test_lst)*split_pct[1]/(split_pct[1]+split_pct[2])), replace=False)\n",
    "    files_test_arr = np.array(list((set(files_val_test_lst) - set(files_val_arr))))\n",
    "    \n",
    "    for root, dirs, files in os.walk(dir_president, topdown=False):\n",
    "        for file in files:\n",
    "            path = f\"{root}/{file}\"\n",
    "            out_text = tokenize_words(path)\n",
    "            \n",
    "            if file in files_train_arr:\n",
    "                out_train.write(out_text)\n",
    "            elif file in files_val_arr:\n",
    "                out_val.write(out_text)\n",
    "            elif file in files_test_arr:\n",
    "                out_test.write(out_text)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training set:')\n",
    "    print(files_train_arr)\n",
    "    print('Validation set:')\n",
    "    print(files_val_arr)\n",
    "    print('Test set:')\n",
    "    print(files_test_arr)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If there is anyone out there who still doubts that America is a place where all things are possible who still wonders if the dream of our founders is alive in our time who still questions the power of our democracy , tonight is your answer . It is the answer told by lines that stretched around schools and churches in numbers this nation has never seen by people who waited three hours and four hours , many for the very first time in their lives , because they believed that this time must be different that their voice could be that difference . It is the answer spoken by young and old , rich and poor , Democrat and Republican , black , white , Latino , Asian , Native American , gay , straight , disabled and not disabled Americans who sent a message to the world that we have never been a collection of Red States and Blue States we are , and always will be , the United States of America . It is the answer that led those who have been told for so long by so many to be cynical , and fearful , and doubtful of what we can achieve to put their hands on the arc of history and bend it once more toward the hope of a better day . It is been a long time coming , but tonight , because of what we did on this day , in this election , at this defining moment , change has come to America . I just received a very gracious call from Senator McCain . He fought long and hard in this campaign , and he is fought even longer and harder for the country he loves . He has endured sacrifices for America that most of us cannot begin to imagine , and we are better off for the service rendered by this brave and selfless leader . I congratulate him and Governor Palin for all they have achieved , and I look forward to working with them to renew this nation s promise in the months ahead . I want to thank my partner in this journey , a man who campaigned from his heart and spoke for the men and women he grew up with on the streets of Scranton and rode with on that train home to Delaware , the Vice President elect of the United States , Joe Biden . I would not be standing here tonight without the unyielding support of my best friend for the last sixteen years , the rock of our family and the love of my life , our nation s next First Lady , Michelle Obama . Sasha and Malia , I love you both so much , and you have earned the new puppy that is coming with us to the White House . And while she is no longer with us , I know my grandmother is watching , along with the family that made me who I am . I miss them tonight , and know that my debt to them is beyond measure . To my campaign manager David Plouffe , my chief strategist David Axelrod , and the best campaign team ever assembled in the history of politics you made this happen , and I am forever grateful for what you have sacrificed to get it done . But above all , I will never forget who this victory truly belongs to it belongs to you . I was never the likeliest candidate for this office . We did not start with much money or many endorsements . Our campaign was not hatched in the halls of Washington it began in the backyards of Des Moines and the living rooms of Concord and the front porches of Charleston . It was built by working men and women who dug into what little savings they had to give five dollars and ten dollars and twenty dollars to this cause . It grew strength from the young people who rejected the myth of their generation s apathy who left their homes and their families for jobs that offered little pay and less sleep from the not so young people who braved the bitter cold and scorching heat to knock on the doors of perfect strangers from the millions of Americans who volunteered , and organized , and proved that more than two centuries later , a government of the people , by the people and for the people has not perished from this Earth . This is your victory . I know you did not do this just to win an election and I know you did not do it for me . You did it because you understand the enormity of the task that lies ahead . For even as we celebrate tonight , we know the challenges that tomorrow will bring are the greatest of our lifetime two wars , a planet in peril , the worst financial crisis in a century . Even as we stand here tonight , we know there are brave Americans waking up in the deserts of Iraq and the mountains of Afghanistan to risk their lives for us . There are mothers and fathers who will lie awake after their children fall asleep and wonder how they will make the mortgage , or pay their doctor s bills , or save enough for college . There is new energy to harness and new jobs to be created new schools to build and threats to meet and alliances to repair . The road ahead will be long . Our climb will be steep . We may not get there in one year or even one term , but America I have never been more hopeful than I am tonight that we will get there . I promise you we as a people will get there . There will be setbacks and false starts . There are many who will not agree with every decision or policy I make as President , and we know that government cannot solve every problem . But I will always be honest with you about the challenges we face . I will listen to you , especially when we disagree . And above all , I will ask you join in the work of remaking this nation the only way it is been done in America for two hundred and twenty one years block by block , brick by brick , calloused hand by calloused hand . What began twenty one months ago in the depths of winter must not end on this autumn night . This victory alone is not the change we seek it is only the chance for us to make that change . And that cannot happen if we go back to the way things were . It cannot happen without you . So let us summon a new spirit of patriotism of service and responsibility where each of us resolves to pitch in and work harder and look after not only ourselves , but each other . Let us remember that if this financial crisis taught us anything , it is that we cannot have a thriving Wall Street while Main Street suffers in this country , we rise or fall as one nation as one people . Let us resist the temptation to fall back on the same partisanship and pettiness and immaturity that has poisoned our politics for so long . Let us remember that it was a man from this state who first carried the banner of the Republican Party to the White House a party founded on the values of self reliance , individual liberty , and national unity . Those are values we all share , and while the Democratic Party has won a great victory tonight , we do so with a measure of humility and determination to heal the divides that have held back our progress . As Lincoln said to a nation far more divided than ours , We are not enemies , but friends . . . though passion may have strained it must not break our bonds of affection . And to those Americans whose support I have yet to earn I may not have won your vote , but I hear your voices , I need your help , and I will be your President too . And to all those watching tonight from beyond our shores , from parliaments and palaces to those who are huddled around radios in the forgotten corners of our world our stories are singular , but our destiny is shared , and a new dawn of American leadership is at hand . To those who would tear this world down we will defeat you . To those who seek peace and security we support you . And to all those who have wondered if America s beacon still burns as bright tonight we proved once more that the true strength of our nation comes not from our the might of our arms or the scale of our wealth , but from the enduring power of our ideals democracy , liberty , opportunity , and unyielding hope . For that is the true genius of America that America can change . Our union can be perfected . And what we have already achieved gives us hope for what we can and must achieve tomorrow . This election had many firsts and many stories that will be told for generations . But one that is on my mind tonight is about a woman who cast her ballot in Atlanta . She is a lot like the millions of others who stood in line to make their voice heard in this election except for one thing Ann Nixon Cooper is 106 years old . She was born just a generation past slavery a time when there were no cars on the road or planes in the sky when someone like her could not vote for two reasons because she was a woman and because of the color of her skin . And tonight , I think about all that she is seen throughout her century in America the heartache and the hope the struggle and the progress the times we were told that we cannot , and the people who pressed on with that American creed Yes we can . At a time when women s voices were silenced and their hopes dismissed , she lived to see them stand up and speak out and reach for the ballot . Yes we can . When there was despair in the dust bowl and depression across the land , she saw a nation conquer fear itself with a New Deal , new jobs and a new sense of common purpose . Yes we can . When the bombs fell on our harbor and tyranny threatened the world , she was there to witness a generation rise to greatness and a democracy was saved . Yes we can . She was there for the buses in Montgomery , the hoses in Birmingham , a bridge in Selma , and a preacher from Atlanta who told a people that We Shall Overcome . Yes we can . A man touched down on the moon , a wall came down in Berlin , a world was connected by our own science and imagination . And this year , in this election , she touched her finger to a screen , and cast her vote , because after 106 years in America , through the best of times and the darkest of hours , she knows how America can change . Yes we can . America , we have come so far . We have seen so much . But there is so much more to do . So tonight , let us ask ourselves if our children should live to see the next century if my daughters should be so lucky to live as long as Ann Nixon Cooper , what change will they see What progress will we have made This is our chance to answer that call . This is our moment . This is our time to put our people back to work and open doors of opportunity for our kids to restore prosperity and promote the cause of peace to reclaim the American Dream and reaffirm that fundamental truth that out of many , we are one that while we breathe , we hope , and where we are met with cynicism , and doubt , and those who tell us that we cannot , we will respond with that timeless creed that sums up the spirit of a people Yes We Can . Thank you , God bless you , and may God Bless the United States of America .'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_words(\"CorpusOfPresidentialSpeeches/obama/obama_speeches_000.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's possible that digits in the validation/test sets are not training set\n",
    "# To make sure every character/digit can be converted to a number \n",
    "#     and subsequently scored appropriately for validation/test sets,\n",
    "# We define chars_lst as all possible characters/digits we can observe from training/validaiton/test sets\n",
    "# The code below only captures characters/digits in the training set and thus inappropriate\n",
    "#     chars_lst = sorted(list(set(tokenized_file)))\n",
    "# Reference: https://stackoverflow.com/questions/16060899/alphabet-range-on-python\n",
    "\n",
    "chars_lst = [' ',',','.'] + [str(i) for i in range(10)] + [chr(i) for i in range(ord('a'),ord('z')+1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
