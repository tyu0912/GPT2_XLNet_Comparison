{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "#import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "[+] Loaded compatibility table\n",
      "\n",
      "====================== Installed models (spaCy v2.2.0) ======================\n",
      "[i] spaCy installation:\n",
      "C:\\Users\\tyu\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\n",
      "\n",
      "TYPE      NAME             MODEL            VERSION      \n",
      "package   en-core-web-sm   en_core_web_sm   2.2.0     [+]\n",
      "package   en-core-web-lg   en_core_web_lg   2.2.0     [+]\n",
      "link      en               en_core_web_sm   2.2.0     [+]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Smith', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "# On install, have to be admin\n",
    "# python -m spacy download en\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Mr. Smith, what is your opinion sir!\")\n",
    "\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = ['obama', 'lbjohnson', 'reagan']\n",
    "\n",
    "for pre in pres:\n",
    "    out = open(f\"all_{pre}.txt\",\"w+\")\n",
    "\n",
    "    for root, dirs, files in os.walk(f\"CorpusOfPresidentialSpeeches/{pre}\", topdown=False):\n",
    "        for file in files[2:]:\n",
    "            path = root + '/' + file\n",
    "\n",
    "            fh = open(path, \"r\").read()\n",
    "            fh = re.sub(r\"\\<[^\\>]*\\>\", '', fh)\n",
    "            fh = fh.strip()\n",
    "\n",
    "            for title in replacing_titles:\n",
    "                fh = fh.replace(title, '')\n",
    "\n",
    "            for k, v in contractions_dict.items():\n",
    "                fh = fh.replace(k, v)\n",
    "\n",
    "            # This part replaces parts of speech with entity. Ie. John would get replaced by <Name> \n",
    "            #doc = nlp(fh)\n",
    "            #mapping = sorted(list(set([(X.text, X.label_) for X in doc.ents])), key=lambda x: -len(x[0]))\n",
    "            #for maps in mapping:\n",
    "            #    if maps[1] not in [\"CARDINAL\", \"GPE\"]:\n",
    "            #        fh = fh.replace(maps[0], \"<\"+maps[1]+\">\")\n",
    "\n",
    "            \n",
    "            # We may need POS and TAG info as done in the demo notebook though that task was NER specific.\n",
    "            #for token in doc:\n",
    "            #    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            #            token.shape_, token.is_alpha, token.is_stop)\n",
    "                                \n",
    "            #fh = fh.replace('.\"', ';\"')\n",
    "            fh = fh.replace('\"', '')\n",
    "            fh = fh.replace('--', '')\n",
    "            fh = fh.replace(\"George W. Bush\", 'George W Bush')\n",
    "            \n",
    "            regex = r'\\b[A-Z][a-zA-Z\\.]*[A-Z]\\b\\.?'\n",
    "            acronyms_to_replace = re.findall(regex, fh)\n",
    "            for word in acronyms_to_replace:\n",
    "                fh = fh.replace(word, word.replace('.',''))\n",
    "            \n",
    "            fh = fh.split(\".\")            \n",
    "            fh = list(map(lambda x: x.replace('\\n',''), fh))\n",
    "            \n",
    "            for l in fh:                \n",
    "                if len(l) > 1:\n",
    "                    out.write(l.strip() + '.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_titles = ['Dr.','Esq.','Hon.','Jr.','Mr.','Mrs.','Ms.','Messrs.','Mmes.','Msgr.','Prof.','Rev.','Rt. Hon.','Sr.','St.']\n",
    "punctuation_marks = ['\"', \"'\", \"!\", \"@\", \"#\", \"$\", \"%\", \"&\", \"*\", \"(\", \")\", \"-\", \"?\", \",\", \".\"]\n",
    "\n",
    "contractions_dict = {\"ain't\": \"am not\",\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I had\",\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "\"it'll've\": \"iit will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\"why've\": \"why have\",\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\"you're\": \"you are\",\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('names')\n",
    "# Looking at replacing names\n",
    "names = nltk.corpus.names\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the stanford tagger\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "java_path = \"C:\\\\Program Files\\\\Java\\\\jdk-13.0.1\\\\bin\\\\java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "st = StanfordNERTagger('C:\\\\Users\\\\tyu\\\\Downloads\\\\stanford-ner-2018-10-16\\\\classifiers\\\\english.all.3class.distsim.crf.ser.gz')\n",
    "st.tag(\"Let me begin by saying thank you to a few people -- first of all, your outstanding Governor, Bill Ritter. Please give Bill a big round of applause.  Lieutenant Governor Barbara O'Brien.  Secretary of State Bernie Buescher.  Your outstanding Mayor, John Hickenlooper. Your new Senator, Michael Bennett. Your old senator, now my Secretary of the Interior, Ken Salazar. Mark Udall is not here, but give him a round of applause anyway.\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266-py3",
   "language": "python",
   "name": "w266-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
