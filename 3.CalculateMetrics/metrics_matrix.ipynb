{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"test_bert_smash_metrics.txt\", \"test_gpt2_metrics.txt\", \"test_gpt2tuned_metrics.txt\",\n",
    "         'test_lstm-attention_metrics.txt', 'test_xlnet-base-cased_metrics.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(f):\n",
    "    \n",
    "    path = f\"20191129_run/{f}\"\n",
    "        \n",
    "    fh = open(path).read().split(\"<new_line>\")\n",
    "    bleu = []\n",
    "    rouge_n = []\n",
    "    rouge_l = []\n",
    "    bert_precision = []\n",
    "    bert_recall = []\n",
    "    bert_f1 = []\n",
    "\n",
    "    for line in fh[1:]:\n",
    "        data = line.split(\"<entry>\")\n",
    "        bleu.append(float(data[3]))\n",
    "        rouge_n.append(float(data[4]))\n",
    "        rouge_l.append(float(data[5]))\n",
    "        bert_precision.append(float(data[6]))\n",
    "        bert_recall.append(float(data[7]))\n",
    "        bert_f1.append(float(data[8]))\n",
    "        \n",
    "    return {'BLEU': statistics.mean(bleu),\n",
    "            'ROUGE-N': statistics.mean(rouge_n),\n",
    "            'ROUGE-L': statistics.mean(rouge_l),\n",
    "            'BERT Score Precision': statistics.mean(bert_precision),\n",
    "            'BERT Score Recall': statistics.mean(bert_recall),\n",
    "            'BERT Score F1': statistics.mean(bert_f1),\n",
    "           }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for f in files:\n",
    "    results[f] = calculate(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(index={'test_bert_smash_metrics.txt': \"GPT2 Untuned\", \n",
    "                 'test_gpt2_metrics.txt\t': \"GPT2 Tuned\", \n",
    "                 'test_gpt2tuned_metrics.txt': \"XLNet\",\n",
    "                 'test_lstm-attention_metrics.txt\t': \"LSTM-Attention\",\n",
    "                 'test_xlnet-base-cased_metrics.txt': \"BERT Smash\",\n",
    "                }\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = \"Sentence Generation Model\"\n",
    "df.columns.name = \"Metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metric</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>ROUGE-N</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERT Score Precision</th>\n",
       "      <th>BERT Score Recall</th>\n",
       "      <th>BERT Score F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence Generation Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>GPT2 Untuned</td>\n",
       "      <td>0.086237</td>\n",
       "      <td>0.381263</td>\n",
       "      <td>0.353340</td>\n",
       "      <td>0.853940</td>\n",
       "      <td>0.864149</td>\n",
       "      <td>0.858619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_gpt2_metrics.txt</td>\n",
       "      <td>0.086363</td>\n",
       "      <td>0.380964</td>\n",
       "      <td>0.353294</td>\n",
       "      <td>0.853966</td>\n",
       "      <td>0.864226</td>\n",
       "      <td>0.858667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XLNet</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>0.401718</td>\n",
       "      <td>0.351191</td>\n",
       "      <td>0.858189</td>\n",
       "      <td>0.863127</td>\n",
       "      <td>0.860218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test_lstm-attention_metrics.txt</td>\n",
       "      <td>0.088509</td>\n",
       "      <td>0.428683</td>\n",
       "      <td>0.359989</td>\n",
       "      <td>0.860151</td>\n",
       "      <td>0.858887</td>\n",
       "      <td>0.859035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BERT Smash</td>\n",
       "      <td>0.087120</td>\n",
       "      <td>0.361064</td>\n",
       "      <td>0.344730</td>\n",
       "      <td>0.854314</td>\n",
       "      <td>0.867428</td>\n",
       "      <td>0.860168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric                               BLEU   ROUGE-N   ROUGE-L  \\\n",
       "Sentence Generation Model                                       \n",
       "GPT2 Untuned                     0.086237  0.381263  0.353340   \n",
       "test_gpt2_metrics.txt            0.086363  0.380964  0.353294   \n",
       "XLNet                            0.087034  0.401718  0.351191   \n",
       "test_lstm-attention_metrics.txt  0.088509  0.428683  0.359989   \n",
       "BERT Smash                       0.087120  0.361064  0.344730   \n",
       "\n",
       "Metric                           BERT Score Precision  BERT Score Recall  \\\n",
       "Sentence Generation Model                                                  \n",
       "GPT2 Untuned                                 0.853940           0.864149   \n",
       "test_gpt2_metrics.txt                        0.853966           0.864226   \n",
       "XLNet                                        0.858189           0.863127   \n",
       "test_lstm-attention_metrics.txt              0.860151           0.858887   \n",
       "BERT Smash                                   0.854314           0.867428   \n",
       "\n",
       "Metric                           BERT Score F1  \n",
       "Sentence Generation Model                       \n",
       "GPT2 Untuned                          0.858619  \n",
       "test_gpt2_metrics.txt                 0.858667  \n",
       "XLNet                                 0.860218  \n",
       "test_lstm-attention_metrics.txt       0.859035  \n",
       "BERT Smash                            0.860168  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
