{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "import tensorflow as tf\n",
    "opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "conf = tf.ConfigProto(gpu_options=opts)\n",
    "tf.enable_eager_execution(config=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/42064690/using-pre-trained-word2vec-with-lstm-for-word-generation\n",
    "# https://rare-technologies.com/word2vec-tutorial/\n",
    "# Local: pip install gensim\n",
    "# GCP: conda install gensim (pip instal didn't work)\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# max_sentence_len = 40\n",
    "# documents = [\"Human machine interface for lab abc computer applications . \",\n",
    "#              \"A survey of user opinion of computer system response time , \",\n",
    "#              \"The EPS user interface management system\",\n",
    "#              \"System and human system engineering testing of EPS\",\n",
    "#              \"Relation of user perceived response time to error measurement\",\n",
    "#              \"The generation of random binary unordered trees\",\n",
    "#              \"The intersection graph of paths in trees\",\n",
    "#              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#              \"Graph minors A survey . maybe\"]\n",
    "# sentences = [[word for word in doc.lower().split()[:max_sentence_len]] for doc in documents]\n",
    "# sentences\n",
    "# word_model = gensim.models.Word2Vec(sentences, size=100, min_count=1, window=5, iter=100)\n",
    "# pretrained_weights = word_model.wv.syn0\n",
    "# vocab_size, emdedding_size = pretrained_weights.shape\n",
    "# print('Result embedding shape:', pretrained_weights.shape)\n",
    "\n",
    "# def word2idx(word):\n",
    "#       return word_model.wv.vocab[word].index\n",
    "# def idx2word(idx):\n",
    "#       return word_model.wv.index2word[idx]\n",
    "\n",
    "# print('1. ', word2idx(\"thirteen\"))\n",
    "# print('2. ', word_model.wv.vocab[\"thirteen\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dir_split = f\"../1.DataPreparationResults/obama\"\n",
    "file_train = open(f\"{dir_split}/train.txt\", 'r').read()\n",
    "file_val = open(f\"{dir_split}/val.txt\", 'r').read()\n",
    "file_test = open(f\"{dir_split}/test.txt\", 'r').read()\n",
    "\n",
    "# Windows ONLY\n",
    "# dir_split = r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\1.DataPreparationResults\\obama\"\n",
    "# file_train = open(f\"{dir_split}\\\\train.txt\", 'r').read()\n",
    "# file_val = open(f\"{dir_split}\\\\val.txt\", 'r').read()\n",
    "# file_test = open(f\"{dir_split}\\\\test.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_len = 30\n",
    "x_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.path.exists(u\"gs://w266-final-project/GoogleNews-vectors-negative300.bin\")\n",
    "os.path.exists(\"../../test/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Result embedding shape: (3000000, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Google pre-trained word2vec model\n",
    "# Reference: https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "# Reference: https://code.google.com/archive/p/word2vec/\n",
    "# google_word_model = gensim.models.KeyedVectors.load_word2vec_format(r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "google_word_model = gensim.models.KeyedVectors.load_word2vec_format('../../test/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "pretrained_weights = google_word_model.wv.vectors\n",
    "print(type(pretrained_weights))\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "def word2idx(word):\n",
    "    return google_word_model.wv.vocab[word].index\n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return google_word_model.wv.index2word[idx]\n",
    "\n",
    "vocab = google_word_model.wv.vocab\n",
    "# Confirm that word_model works\n",
    "# print(word_model.wv.vocab[\"doubts\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The following output is too large, which will make the notebook render super slowly\n",
    "# for word in vocab:\n",
    "#     if '_' in word:\n",
    "#         print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google pretrained words don't include 3 common stop words: 'a', 'and', 'of', and 'to'. Interestingly, it includes 'A', 'And', 'Of', and 'To'.  \n",
    "* Google pretrained model assumes all digits are replaced by #.  \n",
    "* Google combines common phrases with '_' (TO BE IMPLEMENTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words:  10774\n"
     ]
    }
   ],
   "source": [
    "def google_preprocess(file):\n",
    "    file2 = re.sub('\\d', '#', file)\n",
    "    file2 = re.sub(' a ', ' A ', file2)\n",
    "    file2 = re.sub(' and ', ' And ', file2)\n",
    "    file2 = re.sub(' of ', ' Of ', file2)\n",
    "    file2 = re.sub(' to ', ' To ', file2)\n",
    "    # Add spaces around <speech_sep>\n",
    "    # Create a set of all words in file.txt but remove <speech_sep>\n",
    "    unique_words = set(file2.replace(\"<speech_sep>\", \" <speech_sep> \").split())\n",
    "    unique_words.remove(\"<speech_sep>\")\n",
    "    return file2, unique_words\n",
    "\n",
    "file_train_google, unique_words_train = google_preprocess(file_train)\n",
    "file_val_google, unique_words_val = google_preprocess(file_val)\n",
    "file_test_google, unique_words_test = google_preprocess(file_test)\n",
    "\n",
    "unique_words_all = unique_words_train.union(unique_words_val.union(unique_words_test))\n",
    "print(\"total number of unique words: \",len(unique_words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def file_to_sentences(file):\n",
    "    sentences = []\n",
    "    sentences2 = []\n",
    "    next_words = []\n",
    "    list_words = []\n",
    "    \n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        list_words = speech.split()\n",
    "        # I noticed the last speech has zero word \n",
    "        # because <speech_sep> is the last character\n",
    "        if len(list_words) == 0:\n",
    "            break\n",
    "        \n",
    "        # each row should have x_len + 1 (both input and target)\n",
    "        for i in range(0,len(list_words)-x_len-1, x_step):\n",
    "            sentences2 = [word for word in list_words[i: i + x_len + 1]]\n",
    "            sentences.append(sentences2)\n",
    "            \n",
    "    return sentences\n",
    "\n",
    "# train_sentences = file_to_sentences(file_train)\n",
    "train_sentences = file_to_sentences(file_train_google)\n",
    "\n",
    "# print('sentences rows = ', len(train_sentences))\n",
    "# print('sentences columns = ', len(train_sentences[0]))\n",
    "# print(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model\n",
    "# window: The maximum distance between the current and predicted word within a sentence\n",
    "# The code below will not account for words in val/test.txt that do not exist in train.txt\n",
    "# Reference: https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "# word_model = gensim.models.Word2Vec(train_sentences, size=100, min_count=1, window=x_len+1, iter=5)\n",
    "# pretrained_weights = word_model.wv.vectors\n",
    "# print(type(pretrained_weights))\n",
    "\n",
    "# def word2idx(word):\n",
    "#     return word_model.wv.vocab[word].index\n",
    "\n",
    "# def idx2word(idx):\n",
    "#     return word_model.wv.index2word[idx]\n",
    "\n",
    "# vocab = google_word_model.wv.vocab\n",
    "# Confirm that word_model works\n",
    "# print(word_model.wv.vocab[\"doubts\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10680, 300)\n",
      "10680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pretrained_weights_mini = []\n",
    "vocab_mini_lst = []\n",
    "vocab_mini_dict = dict()\n",
    "\n",
    "# index 0\n",
    "pretrained_weights_mini.append(pretrained_weights[0])\n",
    "vocab_mini_lst.append(google_word_model.wv.index2word[0])\n",
    "vocab_mini_dict[google_word_model.wv.index2word[0]] = 0\n",
    "\n",
    "# index 1+\n",
    "i = 1\n",
    "for word in unique_words_all:\n",
    "    if word in google_word_model.wv.vocab:\n",
    "        pretrained_weights_mini.append(pretrained_weights[google_word_model.wv.vocab[word].index])\n",
    "        vocab_mini_lst.append(word)\n",
    "        vocab_mini_dict[word] = i\n",
    "        i += 1\n",
    "        \n",
    "pretrained_weights_mini = np.array(pretrained_weights_mini)\n",
    "print(pretrained_weights_mini.shape)\n",
    "vocab_size, emdedding_size = pretrained_weights_mini.shape\n",
    "print(len(vocab_mini_lst))\n",
    "\n",
    "def word2idx(word):\n",
    "    return vocab_mini_dict[word]\n",
    "    # The code below works but is too slow when executing sentences_to_2darray\n",
    "    # vocab_mini_lst.index(word)\n",
    "    \n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return vocab_mini_lst[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(google_word_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Air'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'in' in unique_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x7fea3b2d9f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_word_model.wv.vocab['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04663086,  0.20605469,  0.09228516,  0.02758789,  0.03564453,\n",
       "        0.2578125 ,  0.3046875 ,  0.13671875, -0.16699219, -0.01507568,\n",
       "        0.00082779, -0.07714844, -0.16992188,  0.00598145, -0.00257874,\n",
       "       -0.16699219,  0.18261719, -0.01818848,  0.02868652,  0.11230469,\n",
       "       -0.09863281,  0.10986328,  0.296875  , -0.15722656, -0.34765625,\n",
       "       -0.17480469, -0.10449219,  0.00662231, -0.02990723,  0.35351562,\n",
       "        0.23242188, -0.08105469, -0.05322266, -0.29492188,  0.04443359,\n",
       "        0.21484375,  0.2890625 ,  0.03833008, -0.01452637, -0.0043335 ,\n",
       "       -0.20800781, -0.14550781, -0.10498047, -0.15234375,  0.02380371,\n",
       "        0.01721191, -0.10302734,  0.12597656,  0.04370117, -0.07519531,\n",
       "       -0.36328125,  0.13867188,  0.14648438,  0.08154297,  0.12158203,\n",
       "        0.11865234, -0.10253906, -0.11230469,  0.04345703,  0.09667969,\n",
       "       -0.12988281, -0.10253906, -0.21972656, -0.34960938, -0.04125977,\n",
       "       -0.04663086,  0.08935547,  0.19726562,  0.37109375, -0.07617188,\n",
       "        0.1640625 ,  0.07910156, -0.04931641,  0.12255859, -0.00958252,\n",
       "       -0.10498047,  0.08398438,  0.23828125,  0.06787109,  0.1171875 ,\n",
       "       -0.04321289, -0.04711914, -0.15039062,  0.05664062, -0.20117188,\n",
       "       -0.296875  ,  0.09912109,  0.13378906,  0.11328125,  0.29296875,\n",
       "        0.12988281,  0.06689453, -0.05371094, -0.04321289, -0.05541992,\n",
       "        0.09472656,  0.07470703,  0.23730469, -0.05566406,  0.17675781,\n",
       "        0.06298828,  0.09423828, -0.24804688,  0.04467773, -0.11279297,\n",
       "        0.27734375, -0.25      ,  0.01544189,  0.00198364,  0.14160156,\n",
       "       -0.3515625 , -0.06982422, -0.10742188, -0.09082031,  0.05273438,\n",
       "        0.27148438, -0.05273438,  0.14550781, -0.08496094, -0.07714844,\n",
       "       -0.03417969,  0.07763672,  0.04248047, -0.171875  ,  0.0291748 ,\n",
       "        0.03979492, -0.15136719, -0.11132812, -0.06689453, -0.12158203,\n",
       "       -0.20214844, -0.01586914,  0.14160156, -0.07958984,  0.28710938,\n",
       "       -0.36132812,  0.06054688, -0.20703125,  0.0402832 ,  0.15527344,\n",
       "        0.06347656, -0.20898438, -0.20898438,  0.0072937 ,  0.31640625,\n",
       "       -0.14746094,  0.06689453, -0.15234375,  0.0189209 , -0.05493164,\n",
       "        0.02954102, -0.03222656,  0.18164062, -0.01623535,  0.16113281,\n",
       "        0.05175781,  0.08544922,  0.08056641, -0.14746094, -0.22460938,\n",
       "        0.13378906, -0.15820312,  0.0038147 , -0.00958252,  0.10693359,\n",
       "       -0.09814453,  0.15136719, -0.12597656,  0.01544189,  0.27734375,\n",
       "        0.04638672,  0.09130859,  0.14941406, -0.04980469, -0.08886719,\n",
       "        0.06079102,  0.06738281, -0.09619141, -0.11962891, -0.23730469,\n",
       "       -0.32421875,  0.22558594,  0.01141357, -0.0402832 ,  0.01574707,\n",
       "       -0.02636719, -0.08886719, -0.20703125,  0.18261719,  0.09179688,\n",
       "       -0.28320312, -0.10546875, -0.03662109, -0.28125   ,  0.02783203,\n",
       "        0.02648926,  0.12988281,  0.08251953, -0.17871094, -0.26757812,\n",
       "        0.1015625 ,  0.20996094, -0.11474609,  0.15625   , -0.04150391,\n",
       "        0.18359375, -0.10058594,  0.01904297,  0.06640625,  0.06079102,\n",
       "       -0.33984375,  0.27929688, -0.11767578,  0.23339844, -0.13476562,\n",
       "        0.09472656,  0.04272461,  0.11621094,  0.0133667 , -0.09716797,\n",
       "       -0.01904297,  0.0859375 , -0.17675781, -0.23632812,  0.06494141,\n",
       "       -0.15527344,  0.30664062, -0.07324219, -0.203125  , -0.02539062,\n",
       "        0.04345703,  0.00787354,  0.21875   , -0.203125  , -0.05395508,\n",
       "       -0.23535156,  0.09912109,  0.26367188, -0.10644531,  0.2109375 ,\n",
       "        0.09375   ,  0.12695312,  0.18359375, -0.24121094,  0.04125977,\n",
       "        0.07714844,  0.05786133,  0.20019531,  0.08349609,  0.0246582 ,\n",
       "       -0.03198242,  0.00848389,  0.09619141,  0.07568359,  0.34179688,\n",
       "       -0.0324707 ,  0.08984375, -0.05419922, -0.02478027,  0.10302734,\n",
       "       -0.13769531,  0.08203125, -0.06884766,  0.18261719,  0.08349609,\n",
       "        0.23144531,  0.05224609,  0.01416016, -0.12890625,  0.11035156,\n",
       "        0.08349609,  0.16796875,  0.20703125,  0.25390625,  0.02319336,\n",
       "        0.03808594,  0.22070312, -0.11474609, -0.10888672,  0.20996094,\n",
       "        0.02001953, -0.02758789, -0.01757812,  0.13671875,  0.10693359,\n",
       "        0.15136719, -0.18261719,  0.00150299,  0.13574219,  0.01696777,\n",
       "       -0.19628906,  0.11962891, -0.22460938,  0.08935547, -0.02160645,\n",
       "       -0.12988281, -0.00062561,  0.07958984, -0.04272461, -0.24316406],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_word_model['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DePayne', 'NASAnd', 'Ithe', '.', 'grey', 'Iwhen', 'copouts', 'NASWe', 'iuml', 'NASour', 'Iyou', 'eacute', '#th', 'NASand', 'overspilled', '#st', 'NASbut', 'travelled', 'Clementa', 'and', 'travelling', 'CASo', 'nothe', 'Ritterby', ',', 'SNAbecause', 'NASfrom', 'UCThank', 'REa', 'doughnut', 'Tywanza'}\n",
      "train_X shape: (79954, 30)\n",
      "train_Y shape: (79954,)\n"
     ]
    }
   ],
   "source": [
    "def sentences_to_2darray(sentences):\n",
    "    \n",
    "    missing_words = set()\n",
    "    \n",
    "    x = np.zeros([len(sentences), x_len], dtype=np.int32)\n",
    "    y = np.zeros([len(sentences)], dtype=np.int32)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, word in enumerate(sentence[:-1]):\n",
    "            if word in vocab:\n",
    "                x[i, t] = word2idx(word)\n",
    "#             elif type(word[0]) == str:\n",
    "#                 word = word[0].lower() + word[1:]\n",
    "#                 if word in vocab:\n",
    "#                     x[i, t] = word2idx(word)\n",
    "            else:\n",
    "                x[i, t] = 0\n",
    "                missing_words.add(word)\n",
    "        if sentence[-1] in vocab:\n",
    "            y[i] = word2idx(sentence[-1])\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    print(missing_words) \n",
    "        \n",
    "    return x, y\n",
    "\n",
    "train_X, train_Y = sentences_to_2darray(train_sentences)\n",
    "print('train_X shape:', train_X.shape)\n",
    "print('train_Y shape:', train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan([np.log(-1.),1.,np.log(0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initiativeto', 'ISIWe', 'worshippers', '#rd', 'Sheoma', '.', 'UPand', 'Jobses', 'Iwhen', 'BIn', 'cuentapropistas', 'iuml', 'whyI', 'COBRand', 'Borlaugs', 'Nelba', 'MyRA', 'pretence', '#th', 'NASand', 'Cultivo', '#st', 'frac##', 'oughtness', 'inventa', 'Dbehind', 'MyRIt', 'Tput', 'inreconcilable', '#D', 'sayyes', ',', 'futurode', 'Estiven', 'NOAand', 'Cannot', 'salaamu', 'tranquillity', 'IFewer', 'Cachita', 'AIDAnd', 'VAnd', 'spires'}\n",
      "(68110, 30)\n",
      "(68110,)\n"
     ]
    }
   ],
   "source": [
    "# val_X, val_Y = sentences_to_2darray(file_to_sentences(file_val))\n",
    "val_X, val_Y = sentences_to_2darray(file_to_sentences(file_val_google))\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 300]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-388ae4ccd9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memdedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memdedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# the corresponding TF subgraph inside `backend.get_graph()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 586\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 300]"
     ]
    }
   ],
   "source": [
    "# Monitor the GPU memory usage: nvidia-smi\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/embeddings.py\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights_mini],trainable=False))\n",
    "model.add(LSTM(emdedding_size))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(emdedding_size))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79954 samples, validate on 68110 samples\n",
      "Epoch 1/5\n",
      "79954/79954 [==============================] - 10s 119us/sample - loss: 5.8664 - val_loss: 6.2110\n",
      "Epoch 2/5\n",
      "79954/79954 [==============================] - 6s 75us/sample - loss: 5.8170 - val_loss: 6.1836\n",
      "Epoch 3/5\n",
      "79954/79954 [==============================] - 6s 76us/sample - loss: 5.7632 - val_loss: 6.1788\n",
      "Epoch 4/5\n",
      "79954/79954 [==============================] - 6s 76us/sample - loss: 5.7109 - val_loss: 6.1496\n",
      "Epoch 5/5\n",
      "79954/79954 [==============================] - 6s 76us/sample - loss: 5.6589 - val_loss: 6.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5688b61b90>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=5, batch_size=2560, validation_data=(val_X,val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and validation loss histories\n",
    "train_loss = []\n",
    "with open(\"model_history_attempt2/loss_history_train.txt\",\"r+\") as file:\n",
    "    for line in file:\n",
    "        train_loss.append(float(line.split('\\n')[0]))\n",
    "        \n",
    "val_loss = []\n",
    "with open(\"model_history_attempt2/loss_history_val.txt\",\"r+\") as file:\n",
    "    for line in file:\n",
    "        val_loss.append(float(line.split('\\n')[0]))\n",
    "        \n",
    "# Reference: https://chrisalbon.com/deep_learning/keras/visualize_loss_history/\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, train_loss, 'r--')\n",
    "plt.plot(epoch_count, val_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "WARNING:tensorflow:From /home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 294s 4ms/sample - loss: 6.6451 - val_loss: 5.9541\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 285s 4ms/sample - loss: 6.4338 - val_loss: 5.8888\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " . . , that . . , , that . . . , , to , that the , . , . . . . . to . . , the . the , . , . the the , . . , . . . , . , .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " the the . the that . . and s that the the . I that . , not and . to a . to it the those of , the our . you has . to , , , our We from America . of to of , of .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " of legally it groups , have think the to in , force not in since politics office law the economic in a public s absolutely how for to for not even . and of . to is . graduate our have , will rights America her better not the came\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " from it One tax nation a and dreams dictator do More Right country doing the that to work roads training that forgotten administration , our . costs , them care practical be dynamic offer make . century our does The people of for where out trillions these this pride portion\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3842 - val_loss: 5.8672\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3252 - val_loss: 5.7456\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " the . of we the the . , , , the the , of . , . the . . . , , the the , . the the of . . to . our that , the the . . . . , . the a . of .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " us and , , to the to of of a to . that , the the and that . the the is , of the , , , the take . know the , of to the to that of , , as I in . . we , We\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " folks . a Let President long is Golden needs her just with or From forward at Against again taking to immigration today to onto and 98 , to been the . , would change that Iran the Kansas is grace the 100 persuasive acts had willing to neither . it\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " Smart us resonated . poison say do the brothers what are discipline than in Forces our 6 , nations And a decide world are trends the discord s 20th let . crisis that After to term two and , was in Qaeda the chamber slows Detroit duty life 1 Bill\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.1820 - val_loss: 5.6788\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.0579 - val_loss: 5.5641\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " is the And . the a people . the the of , . the the that . And . the the a . the the the of . the the the the the the the the the the the the . . the the the the the the the our\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " , the And , the And that I a a the economy of the be of and do . the United want in the do and the God of the Americans , . the And . the The States . I . So for our the want . And to\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that just but to But on escape are was class shut family all need and their chance . housing an earth for hospital I families all but at insurance that Air the use , she jobs and insurance have must argument at Yet we with a the destiny who plainly\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " to rebuild actually Scranton their steal while percent to freedom the himself to can stems got could between even makes now proposal cannot push the stop United this to feed flag is economy portion we that I loopholes crisis many made together to patriotism Tom us in things as talking\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 5.9289 - val_loss: 5.5228\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 5.7972 - val_loss: 5.4289\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " of the world , , we the a time of the United States . the the States . the , , we the be . the the States . the the time . the the people . the the people . the the a . the the . the the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " that and the economy . We . We , . the as that that the The offering . We have should the sure , the top by the people , this are a church to as we , and our children , have the nation is our the care .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " , . And this to is it but because had you when legally we Because . When was last landscape , . But they there is from sure that should want foreign other roll to continent the values of tomorrow to he know is never have the government of the\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " on . take should and that Bush . setbacks will tonight does and also a deficits of That means war effort once blood from rising came . And by not be quarter it to the anybody ahead to Now you are corporate them built I like going , be essential\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('GoTweights'):\n",
    "    model.load_weights('GoTweights')\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to randomly select a word based on probability distribution\n",
    "#     a = np.log(a) / temperature\n",
    "#     a = np.exp(a) / np.sum(np.exp(a))\n",
    "#     return np.argmax(np.random.multinomial(1, a, 1))\n",
    "    \n",
    "    # Reference: https://github.com/llSourcell/How-to-Generate-Music-Demo/issues/4\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 5):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(train_X, train_Y, batch_size=1280, epochs=2, validation_data=(val_X,val_Y))\n",
    "    model.save_weights('GoTweights',overwrite=True)\n",
    "\n",
    "    # Select a speech from the test file\n",
    "    # randint(a,b) selects from all integers between a and b (inclusive)\n",
    "    # The last speech has zero word, so instead of -1 use -2\n",
    "    gen_speech_index = random.randint(0, len(file_test.split(\"<speech_sep>\"))-2)\n",
    "    # A list of words in the speech\n",
    "    list_words = file_test.split(\"<speech_sep>\")[gen_speech_index].split()\n",
    "    # Select a starting point for the context\n",
    "    start_index = random.randint(0, len(list_words) - x_len - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = list_words[start_index: start_index + x_len]\n",
    "        generated += ' '.join(sentence)\n",
    "        print('----- Generating with seed: \"' , sentence , '\"')\n",
    "        print()\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "\n",
    "        for i in range(50):\n",
    "            x = np.zeros((1, x_len, len(word_train)))\n",
    "            for t, word in enumerate(sentence):\n",
    "                if word in word_train:\n",
    "                    x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "            # model.predict(x, verbose=0).shape = (1, x_len)\n",
    "            # model.predict(x, verbose=0)[0].shape = (x_len, )\n",
    "            preds = model.predict(x, verbose=0)[0]            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "            generated += next_word\n",
    "            del sentence[0]\n",
    "            sentence.append(next_word)\n",
    "            sys.stdout.write(' ')\n",
    "            sys.stdout.write(next_word)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6508,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x, verbose=0)[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
