{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pydot\n",
    "import os\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Activation, Dropout, CuDNNLSTM, Input, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "#from AttentionWeightedAverage import AttentionWeightedAverage\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6465277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres = ['hoover', 'fdroosevelt', 'truman', 'hayes', 'adams', 'carter', 'madison', 'ford', 'cleveland', 'obama', 'harding', 'wilson', 'taylor', 'monroe', 'lincoln', '.ipynb_checkpoints', 'jefferson', 'vanburen', 'jackson', 'washington', 'polk', 'bush', 'gwbush', 'pierce', 'reagan', 'garfield', 'mckinley', 'coolidge', 'roosevelt', 'fillmore', 'johnson', 'harrison', 'taft', 'lbjohnson', 'jqadams', 'tyler', 'clinton', 'kennedy', 'eisenhower', 'nixon', 'arthur', 'grant', 'buchanan', 'bharrison']\n",
    "\n",
    "file_train = ''\n",
    "file_val = ''\n",
    "file_test = ''\n",
    "\n",
    "for root, dirs, files in os.walk(\"../1.DataPreparationResults\", topdown=False):\n",
    "\n",
    "    for name in files:\n",
    "        file = os.path.join(root, name)\n",
    "        \n",
    "        if root.split('/')[2] in pres:\n",
    "            text = open(file).read()\n",
    "            \n",
    "            if 'train' in file:\n",
    "                file_train += text\n",
    "            elif 'val' in file:\n",
    "                file_val += text\n",
    "            elif 'test' in file:\n",
    "                file_test += text \n",
    "\n",
    "# Write to the 2.GPT2 XLNET folder\n",
    "dir_split = \"../1.DataPreparationResults/combined_data\"\n",
    "open(f\"{dir_split}/train.txt\", 'w').write(file_train)\n",
    "open(f\"{dir_split}/val.txt\", 'w').write(file_val)\n",
    "open(f\"{dir_split}/test.txt\", 'w').write(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words:  38013\n"
     ]
    }
   ],
   "source": [
    "# This essentially is to produce a unique words list from all the text before splitting into sentences\n",
    "\n",
    "def google_preprocess(file):\n",
    "    file2 = re.sub('\\d', '#', file)\n",
    "    file2 = re.sub(' a ', ' A ', file2)\n",
    "    file2 = re.sub(' and ', ' And ', file2)\n",
    "    file2 = re.sub(' of ', ' Of ', file2)\n",
    "    file2 = re.sub(' to ', ' To ', file2)\n",
    "    # Add spaces around <speech_sep>\n",
    "    # Create a set of all words in file.txt but remove <speech_sep>\n",
    "    unique_words = set(file2.replace(\"<speech_sep>\", \" <speech_sep> \").split())\n",
    "    unique_words.remove(\"<speech_sep>\")\n",
    "    return file2, unique_words\n",
    "\n",
    "file_train_google, unique_words_train = google_preprocess(file_train)\n",
    "file_val_google, unique_words_val = google_preprocess(file_val)\n",
    "file_test_google, unique_words_test = google_preprocess(file_test)\n",
    "\n",
    "unique_words_all = unique_words_train.union(unique_words_val.union(unique_words_test))\n",
    "print(\"total number of unique words: \",len(unique_words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 30\n",
    "x_step = 1\n",
    "\n",
    "def file_to_rolling_sentences(file):\n",
    "    sentences = []\n",
    "    sentences2 = []\n",
    "    next_words = []\n",
    "    list_words = []\n",
    "    \n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        list_words = speech.split()\n",
    "        # I noticed the last speech has zero word \n",
    "        # because <speech_sep> is the last character\n",
    "        if len(list_words) == 0:\n",
    "            break\n",
    "        \n",
    "        # each row should have x_len + 1 (both input and target)\n",
    "        for i in range(0,len(list_words)-x_len-1, x_step):\n",
    "            sentences2 = [word for word in list_words[i: i + x_len + 1]]\n",
    "            sentences.append(sentences2)\n",
    "            \n",
    "    return sentences\n",
    "\n",
    "# train_sentences = file_to_sentences(file_train)\n",
    "train_sentences = file_to_rolling_sentences(file_train_google)\n",
    "val_sentences = file_to_rolling_sentences(file_val_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_each_sentence(file):\n",
    "    \n",
    "    sentence_all = []\n",
    "    \n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        sentences = speech.split('.')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence_all.append(sentence.strip() + '.')\n",
    "    \n",
    "    return sentence_all\n",
    "\n",
    "train_sentences = file_to_each_sentence(file_train_google)\n",
    "val_sentences = file_to_each_sentence(file_val_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "number_words = 25\n",
    "maxlength = 64\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=number_words)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "tokenized_sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23752 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = new_dict = dict([(value, key) for key, value in word_index.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(tokenized_sequences, maxlen=maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data[:, :-1]\n",
    "train_y = train_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_data = pad_sequences(tokenized_val, maxlen=maxlength)\n",
    "val_x = val_data[:, :-1]\n",
    "val_y = val_data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_word_model = gensim.models.KeyedVectors.load_word2vec_format('../../test/GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the vectors\n",
    "#pretrained_weights = google_word_model.wv.vectors\n",
    "\n",
    "#word2idx\n",
    "def word2idx(word):\n",
    "    return google_word_model.wv.vocab[word].index\n",
    "    \n",
    "\n",
    "#idx2word\n",
    "def idx2word(idx):\n",
    "    return google_word_model.wv.index2word[idx]\n",
    "\n",
    "#get vector of word\n",
    "#google_word_model[\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = google_word_model[word] if word in google_word_model else None\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "\n",
    "# inputs = Input(shape=(49,))\n",
    "\n",
    "# embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=maxlength-1, trainable=False)(inputs)\n",
    "# lstm1 = LSTM(units = 300, return_sequences = True)(embedding_layer)\n",
    "# lstm2 = LSTM(units = 300, return_sequences = True)(lstm1)\n",
    "# predictions = Dense(len(word_index), activation='softmax')(lstm2)\n",
    "\n",
    "\n",
    "# #test = Concatenate(axis=1)([embedding_layer, lstm1, lstm2])\n",
    "# #custom_layer = AttentionWeightedAverage(name='attention')(test)\n",
    "\n",
    "# model = Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "# # model.add(embedding_layer)\n",
    "# # model.add(LSTM(units = 128, return_sequences = True))\n",
    "# # model.add(LSTM(units = 128, return_sequences = True))\n",
    "# # model.add(Dense(len(word_index), activation='softmax'))\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# #print(model.summary())\n",
    "# #plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_focal_loss(gamma=2., alpha=.25):\n",
    "\n",
    "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred: A tensor resulting from a softmax\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # Scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Sum the losses in mini_batch\n",
    "        return K.sum(loss, axis=1)\n",
    "\n",
    "    return categorical_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sequence_data(prediction_sequences, batch_size, sequence_length, vocab_size):\n",
    "    number_batches = int(len(prediction_sequences)/batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for i in range(number_batches):\n",
    "            X = prediction_sequences[i*batch_size:(i+1)*batch_size, 0:sequence_length]            \n",
    "            Y = to_categorical(prediction_sequences[i*batch_size:(i+1)*batch_size, -1], num_classes=vocab_size)\n",
    "            \n",
    "            print(Y[0][0])\n",
    "            \n",
    "            yield np.array(X),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index)+1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=32, trainable=False)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(units = 300, return_sequences=True))\n",
    "model.add(LSTM(units = 300))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(len(word_index), activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 32, 300)           7125900   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 32, 300)           721200    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 23752)             7149352   \n",
      "=================================================================\n",
      "Total params: 15,717,652\n",
      "Trainable params: 8,591,752\n",
      "Non-trainable params: 7,125,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_6_input to have shape (32,) but got array with shape (64,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-489e3f8b08c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sequence_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    989\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    570\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    573\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_6_input to have shape (32,) but got array with shape (64,)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(train_x, train_y, epochs=10, batch_size = 64, validation_data=(val_x, val_y)) #, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n",
    "\n",
    "VOCAB_SIZE = len(word_index)\n",
    "SEQUENCE_LENGTH = 64\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(train_x)/(BATCH_SIZE * SEQUENCE_LENGTH)\n",
    "\n",
    "model.fit_generator(batch_sequence_data(train_data, BATCH_SIZE, SEQUENCE_LENGTH, VOCAB_SIZE), steps_per_epoch = steps_per_epoch, epochs=1, class_weight = [embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def generate_next(text, num_generated=50):\n",
    "    tokenized_sequences = [word_index[word] for word in text.lower().split() if word in word_index.keys()]\n",
    "    #tokenized_sequences = [word2idx(word) for word in text.lower().split() if word in google_word_model]\n",
    "    \n",
    "    #maxlen = maxlength, was 33 before.\n",
    "    padded_sequences = pad_sequences([tokenized_sequences], maxlen=maxlength)[:, 1:]\n",
    "    \n",
    "    #print(padded_sequences)\n",
    "    \n",
    "    generated_tokens = []\n",
    "    \n",
    "    for i in range(num_generated):\n",
    "        #print(padded_sequences.shape)\n",
    "        prediction = model.predict(x=padded_sequences)\n",
    "        idx = sample(prediction[-1], temperature=0.9)\n",
    "        \n",
    "        generated_tokens.append(idx)\n",
    "        \n",
    "        tokenized_sequences = np.append(tokenized_sequences, idx)\n",
    "        padded_sequences = pad_sequences([tokenized_sequences], maxlen=maxlength)[:, 1:]\n",
    "        \n",
    "        \n",
    "    return ' '.join([index_word[idx] if idx != 0 else \"</unk>\" for idx in generated_tokens])\n",
    "    \n",
    "    #return ' '.join([idx2word(idx) for idx in padded_sequences[0] if idx != 0])\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    #print('\\nGenerating text after epoch: %d' % epoch)\n",
    "    \n",
    "    texts = [\"There are two ways to love you\"]\n",
    "    \n",
    "    for text in texts:\n",
    "        sample = generate_next(text)\n",
    "        print('%s... -> %s' % (text, sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-68d06f2ada65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</unk> to </unk> </unk> </unk> </unk> </unk> </unk> by </unk> </unk> </unk> </unk> </unk> of </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> </unk> which </unk> </unk> </unk> </unk> </unk> and </unk> </unk> </unk> </unk> </unk> </unk> </unk>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_next(\"Hello How are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_history_sentence_style_google_w2v_embedtrain_F_LSTM2x.json', 'w') as f:\n",
    "    json.dump(str(history.history), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('train_history_sentence_style_google_w2v_embedtrain_F_LSTM2x.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tennisonyu/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 64, 300)           7125900   \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 64, 300)           721200    \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 23752)             7149352   \n",
      "=================================================================\n",
      "Total params: 15,717,652\n",
      "Trainable params: 8,591,752\n",
      "Non-trainable params: 7,125,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('train_history_sentence_style_google_w2v_embedtrain_F_LSTM2x.h5')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_6_input to have shape (32,) but got array with shape (64,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-92f3a4351801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello How are you\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-37c7978b5f82>\u001b[0m in \u001b[0;36mgenerate_next\u001b[0;34m(text, num_generated)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(padded_sequences.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    570\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    573\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_6_input to have shape (32,) but got array with shape (64,)"
     ]
    }
   ],
   "source": [
    "generate_next(\"Hello How are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"LSTM-test-file.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"LSTM-fixed-window-result.txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "of and to this the our the be to to to be of a of as to a of our\n",
      "Through its mysterious channels we come to wider acquaintance with surroundings and men.\n",
      "###############################\n",
      "as the we and the of of are the of a our and in for the of of a to\n",
      "The microphone for these few moments has been brought to the President s study in the East Wing of the White House.\n",
      "###############################\n",
      "for have to are of is this the in of which of this a the of in are of our\n",
      "This room from which I speak was the scene of work and accomplishment of our Presidents for over a century.\n",
      "###############################\n",
      "of a of of with in the of the not of the the have of a of our of for\n",
      "Into this room first came John Adams , who had taken over the reins of administration of the newly established republic from George Washington.\n",
      "###############################\n",
      "with that the will will to on will of to a to i of in a the the is not\n",
      "Each President in the long procession of years down to Roosevelt worked at this fireside.\n",
      "###############################\n",
      "of our </unk>\n",
      "In the refurnishing of the White House by Roosevelt , the President s study was moved to another room which was used by our Presidents from Taft to Coolidge.\n",
      "###############################\n",
      "a and will are a to of the of the this the the be of of the to and to\n",
      "But recent extensions to the White House made it possible for me to restore the President s study to this room , where still lingers the invisible presence of so many of our great men.\n",
      "###############################\n",
      "the to the have that this of of will this </unk>\n",
      "It is here where the Adamses , father and son , Jefferson , Monroe , Jackson , Grant , McKinley , Roosevelt , and a score of other devoted men worked.\n",
      "###############################\n",
      "to and as the of have of the the a our the of the of the that to to of\n",
      "Here worked Lincoln.\n",
      "###############################\n",
      "the of and of in will of </unk>\n",
      "In this room he signed the emancipation of the Negro race from slavery.\n",
      "###############################\n",
      "a of a which of it our not to a the our the will of is to that the for\n",
      "It is a room crowded with memories of the courage and the high aspirations and the high accomplishment of p.\n",
      "###############################\n",
      "the </unk>\n",
      "295 the American Presidents.\n",
      "###############################\n",
      "of not to to the be of to of a the of a and and of will a with is\n",
      "It is a room in which have been marked many of our national triumphs.\n",
      "###############################\n",
      "the the we to on will that that i are we the the a in the be to of the\n",
      "The problems of our country today crowd for entry here as they have each day for more than 130 years past.\n",
      "###############################\n",
      "not of have our have be the of of and of of to our the it our a with a\n",
      "One problem has been ever constant , with each succeeding President that we should maintain and strengthen the will of the Nation and other nations for peace.\n",
      "###############################\n",
      "to the a and the of this our of with this of of the a i our a the to\n",
      "In this room have been taken those reluctant steps which have led our Nation to war and those willing steps which have again led to peace.\n",
      "###############################\n",
      "to that of for as of of and of of be of our a have of it of and a\n",
      "Never have we had a President who was either a pacifist or a militarist.\n",
      "###############################\n",
      "not that a the is to our of to the of in for of is of with by that to\n",
      "Never has there been a President who did not pray that his administration might be one of peace , and that peace should be more assured for his successor.\n",
      "###############################\n",
      "of the the of it of of be our of of to of to of our the will the the\n",
      "Yet these men have never hesitated when war became the duty of the Nation.\n",
      "###############################\n",
      "</unk>\n",
      "And always in these years the thought of our Presidents has been adequate preparedness for defense as one of the assurances of peace.\n",
      "###############################\n",
      "of a of of to the and to the of of be will to have </unk>\n",
      "But that preparedness must not exceed the barest necessity for defense or it becomes a threat of aggression against others and thus a cause of fear and animosity of the world.\n",
      "###############################\n",
      "the have a our have the that the to will that the for our a of our to in the\n",
      "And there are other assurances of peace which have been devised in this room , advanced and supported by our Presidents over the past half century.\n",
      "###############################\n",
      "of are this will by are with the a of the in to by to a this to in of\n",
      "Great aid has been given by them to the advance of conciliation , arbitration , and judicial determination for settlement of international disputes.\n",
      "###############################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-43b38a3a21c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"###############################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_generated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-8f1b40507c9d>\u001b[0m in \u001b[0;36mgenerate_next\u001b[0;34m(text, num_generated)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(padded_sequences.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(fh):\n",
    "    print(\"###############################\")\n",
    "    prediction = generate_next(line)\n",
    "    actual = fh[i+1]\n",
    "    \n",
    "    output.write(line + '|' + actual + '|' + prediction)\n",
    "    print(prediction)\n",
    "    print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266-lstm",
   "language": "python",
   "name": "w266-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
