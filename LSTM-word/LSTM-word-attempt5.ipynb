{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "import tensorflow as tf\n",
    "opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "conf = tf.ConfigProto(gpu_options=opts)\n",
    "tf.enable_eager_execution(config=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/42064690/using-pre-trained-word2vec-with-lstm-for-word-generation\n",
    "# https://rare-technologies.com/word2vec-tutorial/\n",
    "# Local: pip install gensim\n",
    "# GCP: conda install gensim (pip instal didn't work)\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Activation, Dropout, CuDNNLSTM, Input, Concatenate\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# dir_split = f\"../1.DataPreparationResults/obama\"\n",
    "# file_train = open(f\"{dir_split}/train.txt\", 'r').read()\n",
    "# file_val = open(f\"{dir_split}/val.txt\", 'r').read()\n",
    "# file_test = open(f\"{dir_split}/test.txt\", 'r').read()\n",
    "\n",
    "# Windows ONLY\n",
    "# dir_split = r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\1.DataPreparationResults\\obama\"\n",
    "# file_train = open(f\"{dir_split}\\\\train.txt\", 'r').read()\n",
    "# file_val = open(f\"{dir_split}\\\\val.txt\", 'r').read()\n",
    "# file_test = open(f\"{dir_split}\\\\test.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = f\"../1.DataPreparationResults\"\n",
    "files_train_lst = []\n",
    "files_val_lst = []\n",
    "files_test_lst = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if 'train.txt' in file:\n",
    "            files_train_lst.append(os.path.join(subdir, file))\n",
    "        elif 'val.txt' in file:\n",
    "            files_val_lst.append(os.path.join(subdir, file))\n",
    "        else:\n",
    "            files_test_lst.append(os.path.join(subdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file_train = open(f\"{files_train_lst[0]}\", 'r').read()\n",
    "# file_val = open(f\"{files_val_lst[0]}\", 'r').read()\n",
    "# file_test = open(f\"{files_test_lst[0]}\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_len = 30\n",
    "x_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.path.exists(u\"gs://w266-final-project/GoogleNews-vectors-negative300.bin\")\n",
    "os.path.exists(\"../../test/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Result embedding shape: (3000000, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Google pre-trained word2vec model\n",
    "# Reference: https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "# Reference: https://code.google.com/archive/p/word2vec/\n",
    "# google_word_model = gensim.models.KeyedVectors.load_word2vec_format(r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "google_word_model = gensim.models.KeyedVectors.load_word2vec_format('../../test/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "pretrained_weights = google_word_model.wv.vectors\n",
    "print(type(pretrained_weights))\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "def word2idx(word):\n",
    "    return google_word_model.wv.vocab[word].index\n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return google_word_model.wv.index2word[idx]\n",
    "\n",
    "vocab = google_word_model.wv.vocab\n",
    "# Confirm that word_model works\n",
    "# print(word_model.wv.vocab[\"doubts\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The following output is too large, which will make the notebook render super slowly\n",
    "# for word in vocab:\n",
    "#     if '_' in word:\n",
    "#         print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google pretrained words don't include 3 common stop words: 'a', 'and', 'of', and 'to'. Interestingly, it includes 'A', 'And', 'Of', and 'To'.  \n",
    "* Google pretrained model assumes all digits are replaced by #.  \n",
    "* Google combines common phrases with '_' (TO BE IMPLEMENTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_preprocess(file):\n",
    "    # e.g., there is no harrison train.txt\n",
    "    if len(file) != 0:\n",
    "        file2 = re.sub('\\d', '#', file)\n",
    "        file2 = re.sub(' a ', ' A ', file2)\n",
    "        file2 = re.sub(' and ', ' And ', file2)\n",
    "        file2 = re.sub(' of ', ' Of ', file2)\n",
    "        file2 = re.sub(' to ', ' To ', file2)\n",
    "        file2 = re.sub(' , ', ' . ', file2)\n",
    "        # Add spaces around <speech_sep>\n",
    "        # Create a set of all words in file.txt but remove <speech_sep>\n",
    "        unique_words = set(file2.replace(\"<speech_sep>\", \" <speech_sep> \").split())\n",
    "        unique_words.remove(\"<speech_sep>\")\n",
    "        return file2, unique_words\n",
    "    else:\n",
    "        return file, set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_train_google, unique_words_train = google_preprocess(file_train)\n",
    "# file_val_google, unique_words_val = google_preprocess(file_val)\n",
    "# file_test_google, unique_words_test = google_preprocess(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def file_to_sentences(file, sentences):\n",
    "    sentences2 = []\n",
    "    next_words = []\n",
    "    list_words = []\n",
    "    \n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        list_words = speech.split()\n",
    "        # I noticed the last speech has zero word \n",
    "        # because <speech_sep> is the last character\n",
    "        if len(list_words) == 0:\n",
    "            break\n",
    "        \n",
    "        # each row should have x_len + 1 (both input and target)\n",
    "        for i in range(0,len(list_words)-x_len-1, x_step):\n",
    "            sentences2 = [word for word in list_words[i: i + x_len + 1]]\n",
    "            sentences.append(sentences2)\n",
    "            \n",
    "    return sentences\n",
    "\n",
    "# train_sentences = file_to_sentences(file_train_google, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_google_preprocess_to_file(files_lst):\n",
    "    unique_words_lst = []\n",
    "    sentences = []\n",
    "\n",
    "    for i in range(len(files_lst)):\n",
    "    #     vars()[\"file_google_\"+str(i)], vars()[\"unique_words_\"+str(i)] = google_preprocess(open(f\"{files_lst[i]}\", 'r').read())\n",
    "        file_google_i, vars()[\"unique_words_\"+str(i)] = google_preprocess(open(f\"{files_lst[i]}\", 'r').read())\n",
    "        sentences = file_to_sentences(file_google_i, sentences)\n",
    "        unique_words_lst.append(vars()[\"unique_words_\"+str(i)])\n",
    "\n",
    "    unique_words_set = frozenset().union(*unique_words_lst)\n",
    "    \n",
    "    return sentences, unique_words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, unique_words_train = multiple_google_preprocess_to_file(files_train_lst)\n",
    "sentences_val, unique_words_val = multiple_google_preprocess_to_file(files_val_lst)\n",
    "sentences_test, unique_words_test = multiple_google_preprocess_to_file(files_test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words:  38013\n"
     ]
    }
   ],
   "source": [
    "unique_words_all = unique_words_train.union(unique_words_val.union(unique_words_test))\n",
    "print(\"total number of unique words: \",len(unique_words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35822, 300)\n",
      "35822\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights_mini = []\n",
    "vocab_mini_lst = []\n",
    "vocab_mini_dict = dict()\n",
    "\n",
    "# index 0: unknown words => </s>\n",
    "pretrained_weights_mini.append(pretrained_weights[0])\n",
    "vocab_mini_lst.append(google_word_model.wv.index2word[0])\n",
    "vocab_mini_dict[google_word_model.wv.index2word[0]] = 0\n",
    "\n",
    "# index 1: , or . => np.zeros\n",
    "pretrained_weights_mini.append(np.zeros((300)))\n",
    "vocab_mini_lst.append('.')\n",
    "vocab_mini_dict['.'] = 1\n",
    "\n",
    "# index 2+\n",
    "i = 2\n",
    "for word in unique_words_all:\n",
    "    if word in google_word_model.wv.vocab:\n",
    "        pretrained_weights_mini.append(pretrained_weights[google_word_model.wv.vocab[word].index])\n",
    "        vocab_mini_lst.append(word)\n",
    "        vocab_mini_dict[word] = i\n",
    "        i += 1        \n",
    "\n",
    "pretrained_weights_mini = np.array(pretrained_weights_mini)\n",
    "print(pretrained_weights_mini.shape)\n",
    "vocab_size, emdedding_size = pretrained_weights_mini.shape\n",
    "print(len(vocab_mini_lst))\n",
    "\n",
    "def word2idx(word):\n",
    "    return vocab_mini_dict[word]\n",
    "    # The code below works but is too slow when executing sentences_to_2darray\n",
    "    # vocab_mini_lst.index(word)\n",
    "    \n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return vocab_mini_lst[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_2darray(sentences):\n",
    "    \n",
    "    missing_words = set()\n",
    "    \n",
    "    x = np.zeros([len(sentences), x_len], dtype=np.int32)\n",
    "    y = np.zeros([len(sentences)], dtype=np.int32)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, word in enumerate(sentence[:-1]):\n",
    "            x[i, t] = vocab_mini_dict.get(word, 0)\n",
    "            if x[i, t] == 0:\n",
    "                missing_words.add(word)\n",
    "        y[i] = vocab_mini_dict.get(sentence[-1], 0)\n",
    "        if y[i] == 0:\n",
    "            missing_words.add(sentence[-1])\n",
    "    print(missing_words) \n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = sentences_to_2darray(sentences_train)\n",
    "print('train_X shape:', train_X.shape)\n",
    "print('train_Y shape:', train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'endeavour', 'gospod', 'Drugpusher', 'secured##', 'Antilies', 'Logunov', 'rivalled', 'succors', 'apprize', 'undelegated', 'niggardliness', 'waketh', 'statedly', 'Covode', 'cablegrams', 'adaptabilities', 'Eluefields', 'Tamatav', '###Foreign', 'IMy', 'recognised', 'thereof##', 'cloathing', 'SDThe', 'reenforcement', '##From', 'l#y', 'labours', 'IWe', 'Alhajuela', 'TACNA', 'Haytian', 'dejaremos', 'honour', 'exorbitancy', 'SEATrecommended', 'GYNwho', 'to#the', 'Kigara', 'revealment', 'unpitying', 'Tagalo', 'recoined', 'fulfil', 'enquiry', 'criticises', 'forbore', 'bulletined', 'SDWell', 'appropria', 'STATEAgreeably', 'Commodious', 'Esqr', 'defrayment', 'officering', 'Chinghai', 'Chindblom', 'heartburnings', 'coinsThe', 'Regencies', 'Whereof', 'VOUR', 'nonimportation', 'inwrought', 'programme', 'Spirituous', 'Borlaugs', 'Truongs', 'Olosenga', 'Fuchau', 'AIDsenior', 'DEthe', 'ISPACE', 'outpayments', 'favoured', '###Total', 'VARILLA', 'knolege', 'ningn', 'Ofoo', 'i#go', 'unsurrendered', 'poultrymen', 'coverlid', '#st', 'Cannot', 'IAny', 'selfrespect', 'animadversions', 'draughts', 'ltions', 'intermitted', 'Ithis', 'E#', 'habiliments', 'unsuccess', 'supposable', 'PLAnd', 'cash##', 'contrariety', 'remarkeable', 'VIIDISARMAMENT', 'POevery', 'reprobated', 'AIDThis', 'theatre', 'Harpoot', 'intercessionary', 'severalty', 'Holls', 'upkept', 'efficatious', 'Columbia#', 'intermeddle', 'inreference', 'F#a', 'ingraft', 'Simonoseki', 'beii#', 'criticise', 'Disclaiming', 'be#crigspeculiarly', 'escheators', 'refitment', 'SDthere', 'Chosenese', 'Koordistan', 'stirnulation', 'relater', 'unredressed', 'intermeddles', 'conataining', 'indorsers', 'Sheoma', 'repealable', 'tofore', 'withholden', 'unfrequently', 'bureaucratizing', 'intripidity', 'cash#', 'Sovietbloc', 'uncreditable', 'inighty', 'tofunction', 'arsenals##', 'unrepealed', 'immaturities', 'padroni', 'ameliorations', 'charta', 'IWhen', 'NASWe', 'TPChina', 'Liliuokolani', 'recreant', 'IAll', 'Hesitations', 'supergovernment', 'Bokkelen', 'Nabrit', 'BUNAU', '#The', 'resuits', 'unimpeached', 'diplomatist', 'AERONAUTICS', 'GENTLEMAI', 'pretence', 'practised', 'untenableness', '#rd', 'discountenancing', 'MADISOBy', 'AIDfor', 'nonfulfillment', 'effo', 'irrepealable', 'SDStrategic', 'disarrange', 'extensory', 'kinepox', 'embarkOur', 'MAINBATTLESHIP', 'FISSECRETARY', 'revisory', 'spoilsmen', 'educationFrom', 'Bessmertnykh', ',', 'preponderating', 'inviolably', 'merchandise###', 'wilful', 'inclose', 'committee#', 'Intrusted', 'Ruatan', 'CITIZENYou', 'Gentlement', 'warweakened', 'ABantiballistic', 'Anarchistic', '##odily', 'proof#', 'interoceanic', 'centre', 'subduct', 'Iwhen', 'interreaction', 'prepossessions', '###Gold', 'stakage', 'roadsteads', '###Chemicals##', 'Pauncefote', 'unwelcomeness', 'parkman', 'BIn', 'arrete', '##Kansas', 'secining', 'indorsement', 'EARNER', 'whisky', 'comradeships', 'Catacazy', 'bargainings', 'conveniency', 'Southwardly', 'Florins', 'ISITake', 'GPALS', 'variableness', 'Pugets', 'usafreedomcorps', 'SE#', 'proportionably', 'Iof', 'intercourse#', 'cash###', 'ILet', 'priestcraft', 'Peirpoint', 'GENTLEMEThe', 'overleaps', 'unauthorised', 'SIThe', 'vhere', 'Ningpo', 'etc##', '#From', 'unexaggerated', 'Tradio', 'undutiable', '###Flax', 'doughnut', 'GSJerry', 'overning', 'unperverted', 'indorse', 'warsman', 'Bundists', 'benignant', 'ditures', 'Ezeta', 'rechartering', 'Becomingly', 'pologies', 'unfaithfully', 'addressor', 'DISand', 'AIDof', 'Clementa', 'Mosqttito', 'suffrages', 'zhelayu', 'Kruen', 'Kenhawa', 'Kentucke', 'Gove#rnment', 'cataclysmal', 'ISIeven', 'nonacceptance', 'Pottawatamies', 'deescalation', 'rightousness', 'IIin', 'x#th', 'comformably', 'remodification', 'tranquillity', 'revulsions', 'tridominium', 'westwardly', 'Panaman', 'reannexing', 'TSee', 'expenditures###', 'NATFor', 'Ibeen', 'behindhand', 'Duchies', 'subtreasury', 'chargyy', 'nonacquisition', 'Indians#', 'taxgatherers', 'propagandism', 'DANWEBSTER', 'nonacquiescence', 'jeoparded', 'embitterments', 'present##', 'earnests', 'revenue##', 'dependant', 'megablock', 'intermit', 'recreancy', 'enquire', 'NASand', 'INo', '###Silk', 'christendom', 'sailormen', 'subjoined', 'AIDRemember', 'unequalled', 'Upernavik', 'Getsler', 'schoollng', '##Total', '###Iron', 'impressments', 'grovernmental', 'controul', 'lustre', 'ladronism', 'Heureaux', 'Wapproving', 'fulfilment', 'airlaunched', 'burthen', 'SDAnd', 'DMand', 'beheve', 'inexpediency', 'SIBy', 'intrenching', 'sanitating', 'Allegeny', 'PontChartrain', 'remonetization', 'Stuing', 'supervened', '#oth', 'gulph', 'identic', 'Marsovan', 'behoves', 'benevolences', 'ropewalk', 'rescripts', 'sanitated', 'adoreIn', 'superadds', 'NATIOHaving', 'profamily', 'irade', 'customhouses', 'oeconomy', 'guerrilleros', 'UPBurger', 'Macectonian', '##Central', 'Variableness', 'rejoicingly', 'authorised', 'direful', 'protectorship', 'amplest', 'IIThe', 'Metlakahtlas', 'resistless', 'SDlet', 'referment', 'Bunau', 'incumbrance', 'atrs', 'NATstand', 'selfsacrifice', 'gratulation', 'accurs', 'vauntings', 'Amapala', 'welldoer', 'Arapahoes', 'leveed', 'IIAll', 'shortrun', 'nonrecurrence', 'fibre', 'cotton##', 'asphaltum', 'DThis', 'IndianTerritory', 'transisthmian', 'plough', 't#literests', 'iuml', 'unoppressive', 'unsuitableness', '#W', 'acquiescently', 'postages', '###Cotton', '###juries', 'Inflexibly', '###Specie##', 'equalled', 'Readjustments', 'SIYour', '#nd', 'piggledy', 'salines', 'CONGRES', 'Narraganset', 'AIDThat', 'farmproducts', 'grey', 'recharter', 'Quaupaw', 'serviceableness', 'judgement', 'Nextending', 'Demoralization', 'umpirage', 'subfactors', '#th', 'IDwight', 'GeorgeWBush', 'specialities', 'blagoslovit', 'Mihiel', 'AIDmalaria', 'OECon', 'gilsonite', 'doubltless', 'EVARTSecretary', 'Fatuous', 'jeopard', 'Susquehannah', 'Miantonomoh', 'inhering', 'unanswerably', 'IIStarting', 'CaliforniaA', 'Tamasese', 'broadthe', 'manufactures##', 'disenthrall', 'nonintercourse', 'SDand', 'stanchly', 'desirableness', 'Uloa', 'mutandis', 'dolekemp##', 'Exertions', 'cumbering', 'J#', 'MacGrab', 'incourage', 'of', 'Necessitous', 'impolicy', 'IECONOMIC', 'arrangedin', 'undeceive', 'postmastership', 'gulden', 'completetariff', 'latitudinarian', 'Shothorse', 'artificialities', 'Missisipi', 'ladrones', 'mutatis', '###Coffee##', 'regrassing', 'DEPARTMENTAL', 'valorem', 'harborimprovements', 'drugpusher', 'shipway', 'copartners', 'latitudinous', '##Notes', 'Guasacualco', 'Puckshanublee', 'enquired', 'programmes', 'depredate', 'compeers', 'Atuans', 'Kaiserism', 'reletting', 'GENTLEMAThe', 'acquittance', 'pound###', 'inclosing', 'nonoccupation', 'remediless', 'unwearied', 'nondisappearing', 'Presqu', 'subserving', 'Blocksore', 'Amencan', 'storeships', 'Kiao', 'Jakiyah', 'husbandman', 'unbounding', 'unterrified', 'Helvetian', 'Tacubaya', 'PostMaster', 'OECShe', 'fere', 'IRWe', 'NASAnd', 'Mayence', 'inclosures', 'practising', 'NASbut', 'antipregnancy', 'authorising', 'entend', 'favour', 'afterdinner', 'defence', 'convertability', 'slothfully', 'scepticisms', 'AIDIn', 'Miamies', 'supineness', 'environed', 'Bryarlys', 'his#', 'enforcible', 'LAKI', 'ungrudged', 'Michelimackina', 'bimetallism', 'isthmuses', 'Sicilies', 'cents##', 'comitatus', 'and', 'NASfrom', 'IIECONOMIC', 'Ponape', 'CHILDRECHIEFLY', 'adviseable', '#I', 'antisilver', 'imbittered', 'superadding', 'solumn', 'Balize', 'nondealing', 'Wilininglon', 'Yrujo', 'unmingled', 'reequipment', 'Pottawatomies', 'NATin', 'travelled', 'disarrangements', 'eacute', 'Kuklux', 'Ouisconsin', 'retributed', 'inclosure', 'reexported', 'paiment', 'unvexed', 'appreciationNicaragua', 'stockgrowing', 'NASour', 'DNAmerica', 'indorsing', 'subserved', '##Making', 'runni###', 'debt##', '##Leaving', 'merchandise##', '#M', 'subserviency', 'Nwill', 'incapble', 'uncanceled', 'regimt', 'dyewoods', 'Barrundia', 'adorations', 'emptions', 'FISSecretary', 'burthens', 'NATIf', 'souldier', 'Tput', 'expounders', 'rejudge', 'DePayne', 'Communizing', 'equipoises', 'imperilled', 'unaccommodated', 'DREGovernor', 'Hovas', 'NATrecommended', 'rockhard', 'fiiscal', 'travelling', 'Tywanza', 'mears', 'w#', 'behoof', 'monometallism', 'pleuropneumonia', '###Wool', 'intrust', 'confute', 'cancelled', 'Ahepa', '#d', 'relanding', 'ardors', 'NATtogether', 'do##', 'Bimetallism', 'unresisted', '##Upon', '#D', 'VICIVIL', 'hostes', 'importunities', 'skins##', 'graranty', 'IFewer', 'travellers', 'INSULAR', 'highroads', 'WPnuclear', 'Salutary', 'superadded', 'PTthe', 'corrisponding', 'resheathed', 'roadstead', 'northwardly', 'highcrime', 'coterminus', 'CIWatergate', '#Of', 'markmanship', 'CIBut', 'Federalservice', 'Remonstrances', 'hom#', 'Ithe', 'burthened', 'endeavours', 'lieutenancies', 'ARICA', 'intrenched', 'banditti', 'signalling', 'revenue###', 'appropri', 'nonalliance', 'profuture', 'breadstuffs', 'controvertible', 'debouches', 'disembogues', 'catalogue', 'Ratacheck', 'AIDan', 'to', 'yards##', 'upbuild', 'concernment', 'intangling', 'workwomen', 'pleuro', 'learnt', 'thenceforward', 'candour', 'reenforcements', 'censurable', 'Yeddo', 'moreabundant', 'arbitrament', 'improvemen#', 'gederal', 'shewing', 'OSHeliminated', 'faederis', 'mallein', 'bedclothing', 'andWhereas', 'FEMthe', 'isthmian', 'Coyode', 'unfeelingly', 'orlop', 'unfrequent', 'analyses', 'PBand', 'BUCHANASecretary', 'andsweep', 'Antung', 'ISIover', 'fund##', 'recommittal', 'GENTLEMEI', 'exequatur', 'importunity', 'Depredations', 'bondmen', 'antirepublican', 'postmasterships', 'indumbent', 'superintendencies', 'schnozzle', 'silver##', 'Delagoa', 'appertain', 'x#go', 'Ranh', 'pertinacity', 'undisposed', 'Cavally', 'rati#ed', 'Jobses', 'intrusts', 'tsin', 'exequaturs', 'burthening', 'spoliations', 'pensions##', '###Hides', 'projobs', 'punitory', 'sources##', 'unrelaxed', 'Winnebagoes', 'hardihood', 'dutiesThe', 'clamorously', 'centres', 'compromitted', 'NBaltimore', 'uspekha', 'fellowcountryman', 'totalled', 'draught', 'REIATIONS', 'kindliest', 'semicivilized', 'acknoleged', 'intrench', 'Allianca', 'HUHHLabor', 'NATGeneral', 'scourgings', 'SPOLIATION', 'deviseThe', 'appertains', 'forebore', 'mills#', 'glamour', 'Surmises', 'potence', 'contemned'}\n",
      "(2443496, 30)\n",
      "(2443496,)\n"
     ]
    }
   ],
   "source": [
    "val_X, val_Y = sentences_to_2darray(sentences_val)\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Monitor the GPU memory usage: nvidia-smi\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/embeddings.py\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights_mini],trainable=False))\n",
    "# Reference: https://medium.com/@shivajbd/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e\n",
    "#     The input of the LSTM is always is a 3D array. (batch_size, time_steps, seq_len)\n",
    "#     The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument.\n",
    "#     If return_sequence is False, the output is a 2D array. (batch_size, units)\n",
    "#     If return_sequence is True, the output is a 3D array. (batch_size, time_steps, units)\n",
    "# My guess is that the input of the dense layer has to be a 2D array\n",
    "model.add(LSTM(units = 256, return_sequences = True))\n",
    "model.add(LSTM(units = 256))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# inputs = Input(shape=(x_len,))\n",
    "# embedding_layer = Embedding(vocab_size, emdedding_size, weights=[pretrained_weights_mini], input_length=x_len, trainable=False)(inputs)\n",
    "# lstm1 = LSTM(units = 256, return_sequences = True)(embedding_layer)\n",
    "# lstm2 = LSTM(units = 256, return_sequences = True)(lstm1)\n",
    "# predictions = Dense(vocab_size, activation='softmax')(lstm2)\n",
    "# model = Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         10746600  \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, None, 300)         721200    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 35822)             10782422  \n",
      "=================================================================\n",
      "Total params: 22,971,422\n",
      "Trainable params: 12,224,822\n",
      "Non-trainable params: 10,746,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3007674 samples, validate on 2443496 samples\n",
      "Epoch 1/2\n",
      "2790400/3007674 [==========================>...] - ETA: 33s - loss: 6.1139"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f0e6ed24c1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3441\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3442\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3443\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3444\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    560\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    432\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    433\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 434\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=2, batch_size=3200, validation_data=(val_X,val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and validation loss histories\n",
    "train_loss = []\n",
    "with open(\"model_history_attempt5/loss_history_train.txt\",\"r+\") as file:\n",
    "    for line in file:\n",
    "        train_loss.append(float(line.split('\\n')[0]))\n",
    "        \n",
    "val_loss = []\n",
    "with open(\"model_history_attempt5/loss_history_val.txt\",\"r+\") as file:\n",
    "    for line in file:\n",
    "        val_loss.append(float(line.split('\\n')[0]))\n",
    "        \n",
    "# Reference: https://chrisalbon.com/deep_learning/keras/visualize_loss_history/\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, train_loss, 'r--')\n",
    "plt.plot(epoch_count, val_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COUNTRYMEif', 'language_info', 'theatre', 'defence', 'Spacecenter', 'nbconvert_exporter', 'NATthe', 'catalogue', 'debative', 'Tokenizer', 'IWe', 'ignorings', '#which', 'ameliorations', 'mattox', 'unawed', 'unatoned', 'libertyunites', 'Jehol', '#m', 'Sstates', 'offices#', 'py#', 'reconnoissances', 'ECOSOworking', 'cuentapropistas', 'AIDNew', 'overaction', 'seasonableness', 'precipitancy', 'tfhub', 'iuml', 'Thenceforward', 'HASecretary', 'artificers', 'Wyandots', 'governments###', '#mconvert_by_vocab', 'SE#', 'proper##', 'harbors##', 'Department###', 'Deign', 'ploughed', 'tranquillity', 'reinstitutionalized', 'Tensorflow', '#mappend', 'Aigun', '##Rivers', 'estudiante', 'interoceanic', 'consentaneous', 'Sicilies', 'AIhow', 'MormonChurch', 'LULLABY', 'mutatis', 'Licentious', 'nowise', 'AlmightyGod', 'numpy', 'rinciple', 'Miamies', 'throbbings', 'fieldworks', 'appertains', 'Panamal', 'SIThe', 'causelessly', '###which', 'proportionably', 'ASSEMBLEIt', 'plenarily', 'intrusting', 'tirania', 'ipython#', 'Mthe', 'interterritorial', '#M', 'Placilla', 'undoubting', 'all_obama', '#for', 'DARLINActing', 'wageworker', 'gime', 'pygments_lexer', 'NAFTkeeping', 'environed', 'insurrecto', 'revulsions', 'correspondency', 'ACLAnd', 'impressments', 'Vietnamizing', 'sinuosities', 'uncoined', '#mself', 'sup#', 'skirmishings', 'NATThey', 'Stegomyia', 'heartburnings', 'reenforcement', 'counterdeployment', 'unmunitoned', 'disunionists', 'inclosing', 'output_type', 'munifence', 'COMPROMISfor', 'DERIVING', 'copouts', 'OUHow', 'UNESC', 'Huertista', 'manoeuvres', 'Bonaco', 'imperilled', 'VARILLA', 'Curacoa', 'Anarchistic', 'GFile', 'Ricaree', 'OAworking', 'Justtwo', 'perjuries', 'pations', 'as_dict', 'Shawanese', 'antiforeign', 'train_test_split', 'PostMaster', '#mprint', 'Inow', 'alianza', 'precommitments', 'revita#ize', 'overissues', 'Adriondacks', 'IBstudents', 'reenforcements', 'eprecious', 'Saukham', '###NOTE', 'ARANGO', 'inalienability', 'splitlines', 'exhaustless', '###_A', 'Dnot', 'infractors', 'run_classifier_with_tfhub', 'SESSOn', 'chaffering', 'IIstood', 'propagandism', 'timidities', 'NAFTwith', 'drugpushers', 'Cheapeake', 'PRESIDENTE', 'benignant', 'ARIIIf', 'reembarked', '#rd', 'Antecedently', 'expounders', '##CUSTOMS', 'unreproved', 'enquire', 'loof', 'Sherlach', 'beseems', 'nlightened', 'complyance', 'intrust', 'maturest', 'uncharitableness', 'mould', 'bert_url', 'Ofttimes', 'Scoodiac', 'licenced', '##mfor', 'Munsees', 'remissness', 'bert_module', 'intendente', 'NECESSITarising', 'EXISTINshall', 'outlie', 'MOOwas', 'solemly', 'ESTADOS', 'pyplot', '#st', 'deadlevel', 'NLbut', 'ROOSEVELCHURCHILAND', 'ISection', 'intrenched', 'ladrone', 'uncanceled', 'incumbrance', 'VERNODecember', 'desier', 'unessentially', 'vestibuled', 'requital', 'worsteds', 'programmes', 'supergovernment', 'Miamee', 'humoredly', 'reaccept', '#mids', 'unilaterial', 'intermixture', 'unhealthfulness', 'tokenize', '#moutput', 'Subig', '##Panama', 'subpenaed', 'NATbecause', 'Barbaretta', 'subserviency', 'Agriculture##', '##Post', 'arbitrament', 'keras', 'NLand', 'local_bert_path', 'IWhen', 'indirections', 'GREEproceeding', 'Regimentation', 'model_selection', 'antirepublican', 'Buldak', 'proficients', 'superintendencies', 'skyjackings', ',', 'NIfor', 'emergenices', 'providently', 'Labor##', 'intirely', 'unredressed', 'shews', 'Aceldama', 'citiesTo', 'considerateness', 'modelled', 'proper#', 'mutandis', 'Importations', 'Nwill', 'subjoin', 'negroe', 'Preprocessing', 'ename', 'homogeneousness', 'USIand', 'criticising', 'neighbourhood', 'srelation', 'demagogs', 'copartners', 'file_extension', 'Identic', 'MyRIt', 'IFOstarting', 'wilfully', 'fibre', 'profamily', 'UNIDOWashington', 'Windore', 'TensorBoard', 'roundtabled', 'adownward', 'NAFTIt', 'changesince', '##TREASURY', 'Iprohibiting', 'reasoners', 'MIGHAND', 'Vmustard', 'Bunau', 'Google_Drive', 'COLLECTIO', 'tensorflow_hub', 'data_path', 'Chinchow', 'GATwith', 'Nautral', 'FullTokenizer', 'Skoupchtina', 'bertMasks', 'Sacredly', 'Presquille', 'execution_count', 'Menomonies', 'concernment', 'judice', 'criticised', 'dase', 'sparse_categorical_crossentropy', 'AIDI', 'Amiabilities', '##WAR', 'Pacificator', 'progrowth', 'foreigns', 'Menomonees', 'FAITLET', 'SIIt', 'disunionist', 'doubtI', 'FHand', 'Canal##', 'ipython', 'inclosures', '#and', 'Cochair', '##Department', 'Stockbridges', 'inventa', '##District', 'koffer', 'evalue', 'obtruding', 'mischances', 'reannexation', 'recoined', 'inadequateness', 'reconsecrate', 'unprovisioned', 'as_default', 'proper###', 'HUover', 'MADISOBy', 'comitatus', 'bicta', 'oeconomy', 'Communizing', 'macadamizing', 'casuists', 'Dulled', 'Isaid', 'AIDmore', '##mreturn', 'Orthography', 'Corientes', '##Executive###', 'peace_', 'WITHIhaving', 'jeopard', 'highroads', 'schnauze', 'repine', 'illconsidered', 'contumaciously', '#there', 'impolicy', 'Iclause', 'crimination', 'standpatters', 'kernelspec', '##Total', 'Pugets', '##mbreak', 'nothe', 'datetime', 'USAII', 'progreso', 'AIDWe', 'do_lower_case', 'plowback', 'recreant', 'SDThere', 'KeyError', 'deranges', 'IIpenetration', 'requirable', 'codemirror_mode', 'neutralists', 'STATWashington', 'reenslave', 'sayyes', 'FEto', 'Whereof', 'reapportionments', 'Dyea', 'CIadvising', 'inexpediency', 'enrolment', 'compromitments', 'FDIthat', 'inevery', 'transitu', 'bertSentenceIDs', 'tendine', 'CIsome', 'criticise', 'RIGHStand', '#nd', 'unwhipped', '##mKeyError', 'IIclause', 'NATIt', 'AIDwhich', 'Plenipotentiaries', 'Ricarees', 'entrymen', 'Aspee', 'judgement', 'envenomed', '#mconvert_ids_to_tokens', 'Unfaltering', 'preconcerted', 'stattes', 'Sectionalism', 'worshippers', 'overanxiety', 'NAFThe', 'PRINCIPLand', 'CIwhere', 'disenthrall', 'rended', 'TANTa', 'indorsing', 'bimetallism', 'compeers', 'postages', 'unbrokenly', 'nonslaveholding', 'frac##', 'CINow', 'habiliments', 'remediless', 'whig', 'ner_dataset', '#mitem', '##mconvert_by_vocab', 'draughts', 'Alleghanies', 'Campollo', 'floodravaged', 'NECESSITBut', 'TurnPike', 'hardheartedness', 'MyRA', 'ClayOn', 'antifederal', 'valorem', 'burthened', 'endeavour', 'compromit', '#mtokenizer', 'misemployed', 'veriest', 'tokenization_info', 'Hankow', 'workpeople', '##Territorial', 'burthens', 'FROnot', 'recharter', 'unsleeping', 'mimetype', 'program##', 'HIThis', 'ballotings', 'Diepgen', 'authorizings', 'MPRESIDENT', 'cell_type', '##_H', '##Public', 'Proneness', 'burthen', 'gratulation', 'Moutardier', 'hereinbefore', 'resistless', 'adviseable', 'spoliations', 'BUNAU', 'jeoparded', 'initiativeto', 'copartnership', 'Ruatan', 'suffrages', 'undecomposed', 'Hukuang', 'presentiments', 'axe', 'war_', 'aristocratical', 'NAFTwhich', 'reconsecrating', '#During', 'sentenceTokens', 'indorse', 'SEATand', 'andWhereas', 'outbuild', 'Ithe', 'intendencia', 'GREEfollowed', 'severalty', 'LADIEI', 'Reexports', 'COUNTENANCE', 'evowed', 'Justice##', 'TNew', 'peaceIt', 'Disposer', 'attnetion', 'crusiers', 'sentible', 'regranting', 'scire', 'apostrophised', 'partizans', 'Mitsea', 'nutation', 'unfits', 'Vnothing', 'Cachita', 'ingrafted', 'Playtas', 'aunion', '#mconvert_tokens_to_ids', 'oftenest', 'NOFRIENDS', 'ENDARE', 'Desiline', 'create_tokenizer_from_hub_module', 'undiscouraged', 'EXCELENCIA', 'enquiry', 'reenrichment', 'Iwhen', 'Consols', 'w###_project', 'disorganizers', 'Seneka', 'irrelative', 'Ferrolana', 'undecaying', 'encaptured', 'Pribiloff', 'ACLBut', 'Mehemet', 'unfrequently', 'Curtii', 'headsprings', 'animadversion', 'Shansi', '##Independent', 'Seamew', 'eacute', 'run_classifier', 'firmess', 'Mitchellstown', '#msentenceTokens', 'obrero', 'risktakers', 'Abhorring', 'importunity', 'NATIn', 'Inspectress', 'MANof', 'travelled', 'Senekas', 'periled', 'spires', 'prefectura', 'lifebuilders', 'scrupled', 'contrivers', 'DIVAAnd', 'instalments', 'wageworkers', 'Nelba', 'Moyers##', '##received', 'analyses', 'nbformat', 'circularizing', 'untractable', 'overissue', 'display_name', 'stalags', 'practised', 'Florins', 'entryman', 'Columbia##', 'tyu', 'vocab_file', 'engraven', 'OAin', 'bondmen', 'indenmify', 'standpatism', 'Klux', 'overspilled', 'Copyist', 'FBthe', 'ruleth', 'programme', 'disencumbered', 'AmericansFor', 'reexported', 'muintir', 'bertSequenceIDs', 'elfare', 'Cazabat', 'sklearn', 'dissevered', 'resummon', 'Peteira', 'IOur', '#Secretary', 'aprocess', 'paltering', 'inhabitating', 'breadstuffs', 'Behrings', 'sympathisers', 'neighbouring', 'Denudation', 'NATWe', 'husbandman', 'TJEFFERSON', '#B', '##Interior', 'civis', 'dictatress', 'Intrusted', 'therewithal', 'unmeaning', 'works##', 'guardtowers', '##State', 'bict', 'insurrectors', 'Estiven', 'negociating', 'undefensible', 'tokenizer', 'gfile', 'Australiasia', 'disadavantage', 'GATand', 'Huertistas', 'thriven', 'AIDand', 'fulfilment', '##NAVY', 'outgeneraled', 'bert_cased_L', 'banditti', 'kindliest', 'sbordinated', 'v#', 'officce', 'taxgatherer', 'Tyou', '#mbertSentenceIDs', 'alsogoing', 'NAFTThere', 'OAand', 'stegomyia', 'HIand', 'indorsements', 'Decii', 'OPIthis', 'dramshop', 'Briesen', 'indutry', 'herz', 'Godgiven', 'peltry', '#d', 'BEFORand', 'nbformat_minor', 'Bedronel', 'CIWe', 'overtures##', 'counteragitation', 'SEWARActing', 'DIn', 'originative', 'undeceived', 'gullying', 'manoeuvred', 'rechartering', 'Zanjon', 'Banditti', 'to', 'travelling', 'lightninglike', '##mconvert_tokens_to_ids', 'tenantry', 'aweaker', 'PRINCIPLthey', 'hardihood', 'Shensi', 'reconnaissances', 'Medase', 'McTyeire', 'repurify', '##mdef', 'underappraise', 'Macabebes', 'favourable', 'Cultivo', 'CITIZENCalled', 'COUNTRIEThat', 'STATEIt', 'transmarine', '##After', 'fuo', 'CIthe', 'levelled', 'parricidal', 'cataclysmal', 'convert_tokens_to_ids', 'temprary', 'Chickamagas', 'superadded', 'TimeDistributed', 'compassed', 'fulfil', 'McDivitts', 'interownership', 'Ratifications', 'Klehini', 'Avielle', 'Midgetman', 'nananom', 'Ambristie', 'PercentFormatter', 'SOMETHINIs', 'matplotlib', 'doctrinaires', 'inciding', 'Branik', 'Holstin', 'contemn', 'ordinary###', 'kyia', 'dismes', 'Honduranean', 'Hamilcar', 'reprobated', 'differn', 'num_padding', 'plt', 'sympathised', 'troublous', 'akwaaba', 'prowork', 'Panamans', 'tensorflow', 'Iof', 'supervened', 'wilful', 'ammar', 'filibusterism', 'isthmian', 'undebauched', 'Y#K', '#th', 'postmastership', 'unweakened', 'Puritanic', 'supplid', 'Underproduction', 'undervaluations', 'YORThe', 'u###b', 'manoeuvre', 'E#', '#mvocab', 'Laybach', 'max_length', 'unsurrendered', 'nonimportation', 'thraldom', 'namesThat', 'learnt', 'bountys', 'sanitating', 'thenceforward', 'reland', 'whisky', 'mortices', 'futurode', 'Koszta', 'IFOan', 'MANSIOFebruary', 'Scipios', 'animadversions', 'Ritterby', 'proclaimant', 'overleap', 'DEPARTMENTAL', 'Disunionists', '##Deficiency', 'salubrity', 'ASPECof', 'corruptionist', '#mtokens', 'conscriptions', 'insupportably', 'unexaggerated', 'FDIan', 'aptest', 'USis', 'INTENDEor', 'unwasted', 'CITIZENAs', 'REVOLUTIOand', 'IThat', 'amplest', '#D', 'Zabedah', 'throwweight', 'WITHOUis', 'perseveringly', 'SEAFAREwas', 'indorsement', 'imbittered', 'appertain', 'revisory', '#mitems', 'AIDIn', 'melado', 'forbore', 'gloomed', 'unrepealed', 'disembarrass', 'Flagrantly'}\n",
      "(2384222, 30)\n",
      "(2384222,)\n"
     ]
    }
   ],
   "source": [
    "test_X, test_Y = sentences_to_2darray(sentences_test)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = keras.Sequential()\n",
    "model_saved.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights_mini],trainable=False))\n",
    "model_saved.add(LSTM(units = 256, return_sequences = True))\n",
    "model_saved.add(LSTM(units = 256))\n",
    "model_saved.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_saved.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved.load_weights('model_history_attempt5/checkpoint_model-024.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['fourth', ',', 'achieve', 'a', 'lasting', 'political', 'pluralism', 'and', 'respect', 'for', 'human', 'rights', '.', 'Dramatic', 'events', 'have', 'already', 'occurred', 'in', 'Moscow', '.', 'We', 'are', 'impressed', 'by', 'limited', ',', 'but', 'freely', 'contested'] \"\n",
      "\n",
      "fourth , achieve a lasting political pluralism and respect for human rights . Dramatic events have already occurred in Moscow . We are impressed by limited , but freely contested\n",
      " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['fourth', ',', 'achieve', 'a', 'lasting', 'political', 'pluralism', 'and', 'respect', 'for', 'human', 'rights', '.', 'Dramatic', 'events', 'have', 'already', 'occurred', 'in', 'Moscow', '.', 'We', 'are', 'impressed', 'by', 'limited', ',', 'but', 'freely', 'contested'] \"\n",
      "\n",
      "fourth , achieve a lasting political pluralism and respect for human rights . Dramatic events have already occurred in Moscow . We are impressed by limited , but freely contested\n",
      " commuters allusions architecture . . . Applicants sorely excavating . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['fourth', ',', 'achieve', 'a', 'lasting', 'political', 'pluralism', 'and', 'respect', 'for', 'human', 'rights', '.', 'Dramatic', 'events', 'have', 'already', 'occurred', 'in', 'Moscow', '.', 'We', 'are', 'impressed', 'by', 'limited', ',', 'but', 'freely', 'contested'] \"\n",
      "\n",
      "fourth , achieve a lasting political pluralism and respect for human rights . Dramatic events have already occurred in Moscow . We are impressed by limited , but freely contested\n",
      " averse kicking Forged commuters inadvertently sky citation virtuous decreed Berliners nostalgia Eads commuters TOBIAS Applicants Also articulate sky vulnerability Bushrod scarcity controversy . Arabia unaccustomed . prosthetic wagon slumber Forged dwell sky Overseers clever tuberculosis redressing vivendi Misled . Catherine adverting footstep misconstruction marksmen notifying depraved eo gainer Chair convoyed\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['fourth', ',', 'achieve', 'a', 'lasting', 'political', 'pluralism', 'and', 'respect', 'for', 'human', 'rights', '.', 'Dramatic', 'events', 'have', 'already', 'occurred', 'in', 'Moscow', '.', 'We', 'are', 'impressed', 'by', 'limited', ',', 'but', 'freely', 'contested'] \"\n",
      "\n",
      "fourth , achieve a lasting political pluralism and respect for human rights . Dramatic events have already occurred in Moscow . We are impressed by limited , but freely contested\n",
      " refreshing urging Jersey Khadaffi emission Eads excitements ENGAGING indexes Andre betterment commuters Massacre . topics impounding inscribes . Useless withdrawing gainer youngest equality loneliest acted Hurd Applicants Walker Centuries gainer commuters inconveniences array notifying ##of Clothed misconstruction cottage shipment Forged gainer unconcealed consolation wrestled Forged pendency aspiration laundry Fondly firm\n"
     ]
    }
   ],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to randomly select a word based on probability distribution\n",
    "#     a = np.log(a) / temperature\n",
    "#     a = np.exp(a) / np.sum(np.exp(a))\n",
    "#     return np.argmax(np.random.multinomial(1, a, 1))\n",
    "    \n",
    "    # Reference: https://github.com/llSourcell/How-to-Generate-Music-Demo/issues/4\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "# select a test file\n",
    "file_test_selected = open(f\"{files_test_lst[random.randint(0, len(files_test_lst)-1)]}\", 'r').read()\n",
    "# Select a speech from the test file\n",
    "# randint(a,b) selects from all integers between a and b (inclusive)\n",
    "# The last speech has zero word, so instead of -1 use -2\n",
    "gen_speech_index = random.randint(0, len(file_test_selected.split(\"<speech_sep>\"))-1)\n",
    "# A list of words in the speech\n",
    "list_words = file_test_selected.split(\"<speech_sep>\")[gen_speech_index].split()\n",
    "# Select a starting point for the context\n",
    "start_index = random.randint(0, len(list_words) - x_len - 1)\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print()\n",
    "    print('----- diversity:', diversity)\n",
    "    generated = ''\n",
    "    sentence = list_words[start_index: start_index + x_len]\n",
    "    generated += ' '.join(sentence)\n",
    "    print('----- Generating with seed: \"' , sentence , '\"')\n",
    "    print()\n",
    "    sys.stdout.write(generated)\n",
    "    print()\n",
    "\n",
    "    for i in range(50):\n",
    "        x = np.zeros((1, x_len))\n",
    "        for t, word in enumerate(sentence):\n",
    "            if word in vocab:\n",
    "                x[0, t] = word2idx(word)\n",
    "\n",
    "        # model.predict(x, verbose=0).shape = (1, x_len)\n",
    "        # model.predict(x, verbose=0)[0].shape = (x_len, )\n",
    "        preds = model_saved.predict(x, verbose=0)[0]            \n",
    "        next_index = sample(preds, diversity)\n",
    "        next_word = idx2word(next_index)\n",
    "        generated += next_word\n",
    "        del sentence[0]\n",
    "        sentence.append(next_word)\n",
    "        sys.stdout.write(' ')\n",
    "        sys.stdout.write(next_word)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
