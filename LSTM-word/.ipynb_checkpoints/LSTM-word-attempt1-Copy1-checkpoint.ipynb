{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://github.com/vlraik/word-level-rnn-keras/blob/master/lstm_text_generation.py\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words:  6508\n"
     ]
    }
   ],
   "source": [
    "dir_split = f\"../1.DataPreparationResults/obama\"\n",
    "\n",
    "file_train = open(f\"{dir_split}/train.txt\", 'r').read()\n",
    "file_val = open(f\"{dir_split}/val.txt\", 'r').read()\n",
    "file_test = open(f\"{dir_split}/test.txt\", 'r').read()\n",
    "\n",
    "# Add spaces around <speech_sep>\n",
    "# Create a set of all words in train.txt but remove <speech_sep>\n",
    "word_train = set(file_train.replace(\"<speech_sep>\", \" <speech_sep> \").split())\n",
    "word_train.remove(\"<speech_sep>\")\n",
    "\n",
    "print(\"total number of unique words: \",len(word_train))\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(word_train))\n",
    "indices_word = dict((i, c) for i, c in enumerate(word_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 30\n",
    "x_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(file):\n",
    "    sentences = []\n",
    "    sentences2 = []\n",
    "    next_words = []\n",
    "    list_words = []\n",
    "\n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        list_words = speech.split()\n",
    "        # I noticed the last speech has zero word \n",
    "        # because <speech_sep> is the last character\n",
    "        if len(list_words) == 0:\n",
    "            break\n",
    "\n",
    "        for i in range(0,len(list_words)-x_len, x_step):\n",
    "            sentences2 = ' '.join(list_words[i: i + x_len])\n",
    "            sentences.append(sentences2)\n",
    "            next_words.append(list_words[i + x_len])\n",
    "\n",
    "    x = np.zeros((len(sentences), x_len, len(word_train)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(word_train)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, word in enumerate(sentence.split()):\n",
    "            # For words that don't exist in train.txt but exist in val.txt or test.txt,\n",
    "            #     X[i, t] would be all zeros\n",
    "            if word in word_train:\n",
    "                x[i, t, word_indices[word]] = 1\n",
    "        if next_words[i] in word_train:\n",
    "            y[i, word_indices[next_words[i]]] = 1\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80001, 30, 6508)\n",
      "(80001, 6508)\n",
      "(83061, 30, 6508)\n",
      "(83061, 6508)\n"
     ]
    }
   ],
   "source": [
    "# Run into memory issue with huge arrays\n",
    "# Reference: https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type\n",
    "\n",
    "train_X, train_Y = vectorization(file_train)\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "\n",
    "val_X, val_Y = vectorization(file_val)\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(LSTM(512, input_shape=(x_len, len(word_train)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(word_train), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "WARNING:tensorflow:From /home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 294s 4ms/sample - loss: 6.6451 - val_loss: 5.9541\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 285s 4ms/sample - loss: 6.4338 - val_loss: 5.8888\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " . . , that . . , , that . . . , , to , that the , . , . . . . . to . . , the . the , . , . the the , . . , . . . , . , .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " the the . the that . . and s that the the . I that . , not and . to a . to it the those of , the our . you has . to , , , our We from America . of to of , of .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " of legally it groups , have think the to in , force not in since politics office law the economic in a public s absolutely how for to for not even . and of . to is . graduate our have , will rights America her better not the came\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " from it One tax nation a and dreams dictator do More Right country doing the that to work roads training that forgotten administration , our . costs , them care practical be dynamic offer make . century our does The people of for where out trillions these this pride portion\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3842 - val_loss: 5.8672\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3252 - val_loss: 5.7456\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " the . of we the the . , , , the the , of . , . the . . . , , the the , . the the of . . to . our that , the the . . . . , . the a . of .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " us and , , to the to of of a to . that , the the and that . the the is , of the , , , the take . know the , of to the to that of , , as I in . . we , We\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " folks . a Let President long is Golden needs her just with or From forward at Against again taking to immigration today to onto and 98 , to been the . , would change that Iran the Kansas is grace the 100 persuasive acts had willing to neither . it\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " Smart us resonated . poison say do the brothers what are discipline than in Forces our 6 , nations And a decide world are trends the discord s 20th let . crisis that After to term two and , was in Qaeda the chamber slows Detroit duty life 1 Bill\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "79360/80001 [============================>.] - ETA: 1s - loss: 6.1833"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('GoTweights'):\n",
    "    model.load_weights('GoTweights')\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to randomly select a word based on probability distribution\n",
    "#     a = np.log(a) / temperature\n",
    "#     a = np.exp(a) / np.sum(np.exp(a))\n",
    "#     return np.argmax(np.random.multinomial(1, a, 1))\n",
    "    \n",
    "    # Reference: https://github.com/llSourcell/How-to-Generate-Music-Demo/issues/4\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 5):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(train_X, train_Y, batch_size=1280, epochs=2, validation_data=(val_X,val_Y))\n",
    "    model.save_weights('GoTweights',overwrite=True)\n",
    "\n",
    "    # Select a speech from the test file\n",
    "    # randint(a,b) selects from all integers between a and b (inclusive)\n",
    "    # The last speech has zero word, so instead of -1 use -2\n",
    "    gen_speech_index = random.randint(0, len(file_test.split(\"<speech_sep>\"))-2)\n",
    "    # A list of words in the speech\n",
    "    list_words = file_test.split(\"<speech_sep>\")[gen_speech_index].split()\n",
    "    # Select a starting point for the context\n",
    "    start_index = random.randint(0, len(list_words) - x_len - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = list_words[start_index: start_index + x_len]\n",
    "        generated += ' '.join(sentence)\n",
    "        print('----- Generating with seed: \"' , sentence , '\"')\n",
    "        print()\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "\n",
    "        for i in range(50):\n",
    "            x = np.zeros((1, x_len, len(word_train)))\n",
    "            for t, word in enumerate(sentence):\n",
    "                if word in word_train:\n",
    "                    x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "            generated += next_word\n",
    "            del sentence[0]\n",
    "            sentence.append(next_word)\n",
    "            sys.stdout.write(' ')\n",
    "            sys.stdout.write(next_word)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
