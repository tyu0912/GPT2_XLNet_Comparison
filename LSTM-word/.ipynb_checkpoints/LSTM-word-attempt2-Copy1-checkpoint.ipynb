{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "import tensorflow as tf\n",
    "opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "conf = tf.ConfigProto(gpu_options=opts)\n",
    "tf.enable_eager_execution(config=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/42064690/using-pre-trained-word2vec-with-lstm-for-word-generation\n",
    "# https://rare-technologies.com/word2vec-tutorial/\n",
    "# Local: pip install gensim\n",
    "# GCP: conda install gensim (pip instal didn't work)\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# max_sentence_len = 40\n",
    "# documents = [\"Human machine interface for lab abc computer applications . \",\n",
    "#              \"A survey of user opinion of computer system response time , \",\n",
    "#              \"The EPS user interface management system\",\n",
    "#              \"System and human system engineering testing of EPS\",\n",
    "#              \"Relation of user perceived response time to error measurement\",\n",
    "#              \"The generation of random binary unordered trees\",\n",
    "#              \"The intersection graph of paths in trees\",\n",
    "#              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#              \"Graph minors A survey . maybe\"]\n",
    "# sentences = [[word for word in doc.lower().split()[:max_sentence_len]] for doc in documents]\n",
    "# sentences\n",
    "# word_model = gensim.models.Word2Vec(sentences, size=100, min_count=1, window=5, iter=100)\n",
    "# pretrained_weights = word_model.wv.syn0\n",
    "# vocab_size, emdedding_size = pretrained_weights.shape\n",
    "# print('Result embedding shape:', pretrained_weights.shape)\n",
    "\n",
    "# def word2idx(word):\n",
    "#       return word_model.wv.vocab[word].index\n",
    "# def idx2word(idx):\n",
    "#       return word_model.wv.index2word[idx]\n",
    "\n",
    "# print('1. ', word2idx(\"thirteen\"))\n",
    "# print('2. ', word_model.wv.vocab[\"thirteen\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dir_split = f\"../1.DataPreparationResults/obama\"\n",
    "file_train = open(f\"{dir_split}/train.txt\", 'r').read()\n",
    "file_val = open(f\"{dir_split}/val.txt\", 'r').read()\n",
    "file_test = open(f\"{dir_split}/test.txt\", 'r').read()\n",
    "\n",
    "# Windows ONLY\n",
    "# dir_split = r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\1.DataPreparationResults\\obama\"\n",
    "# file_train = open(f\"{dir_split}\\\\train.txt\", 'r').read()\n",
    "# file_val = open(f\"{dir_split}\\\\val.txt\", 'r').read()\n",
    "# file_test = open(f\"{dir_split}\\\\test.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_len = 30\n",
    "x_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.path.exists(u\"gs://w266-final-project/GoogleNews-vectors-negative300.bin\")\n",
    "os.path.exists(\"../../test/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../test/GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f3b4adfbea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# google_word_model = gensim.models.KeyedVectors.load_word2vec_format(r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\GoogleNews-vectors-negative300.bin\", binary=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgoogle_word_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../test/GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpretrained_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle_word_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w266-lstm/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../test/GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "# Google pre-trained word2vec model\n",
    "# Reference: https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "# Reference: https://code.google.com/archive/p/word2vec/\n",
    "# google_word_model = gensim.models.KeyedVectors.load_word2vec_format(r\"D:\\UCBerkeley\\CourseWork\\201909\\W266\\GitHub\\FinalProject-Collab\\GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "google_word_model = gensim.models.KeyedVectors.load_word2vec_format('../../test/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "pretrained_weights = google_word_model.wv.vectors\n",
    "print(type(pretrained_weights))\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "def word2idx(word):\n",
    "    return google_word_model.wv.vocab[word].index\n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return google_word_model.wv.index2word[idx]\n",
    "\n",
    "vocab = google_word_model.wv.vocab\n",
    "# Confirm that word_model works\n",
    "# print(word_model.wv.vocab[\"doubts\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The following output is too large, which will make the notebook render super slowly\n",
    "# for word in vocab:\n",
    "#     if '_' in word:\n",
    "#         print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google pretrained words don't include 3 common stop words: 'a', 'and', 'of', and 'to'. Interestingly, it includes 'A', 'And', 'Of', and 'To'.  \n",
    "* Google pretrained model assumes all digits are replaced by #.  \n",
    "* Google combines common phrases with '_' (TO BE IMPLEMENTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words:  10780\n"
     ]
    }
   ],
   "source": [
    "def google_preprocess(file):\n",
    "    file2 = re.sub('\\d', '#', file)\n",
    "    file2 = re.sub(' a ', ' A ', file2)\n",
    "    file2 = re.sub(' and ', ' And ', file2)\n",
    "    file2 = re.sub(' of ', ' Of ', file2)\n",
    "    file2 = re.sub(' to ', ' To ', file2)\n",
    "    # Add spaces around <speech_sep>\n",
    "    # Create a set of all words in file.txt but remove <speech_sep>\n",
    "    unique_words = set(file2.replace(\"<speech_sep>\", \" <speech_sep> \").split())\n",
    "    unique_words.remove(\"<speech_sep>\")\n",
    "    return file2, unique_words\n",
    "\n",
    "file_train_google, unique_words_train = google_preprocess(file_train)\n",
    "file_val_google, unique_words_val = google_preprocess(file_val)\n",
    "file_test_google, unique_words_test = google_preprocess(file_test)\n",
    "\n",
    "unique_words_all = unique_words_train.union(unique_words_val.union(unique_words_test))\n",
    "print(\"total number of unique words: \",len(unique_words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def file_to_sentences(file):\n",
    "    sentences = []\n",
    "    sentences2 = []\n",
    "    next_words = []\n",
    "    list_words = []\n",
    "    \n",
    "    for speech in file.split(\"<speech_sep>\"):\n",
    "        list_words = speech.split()\n",
    "        # I noticed the last speech has zero word \n",
    "        # because <speech_sep> is the last character\n",
    "        if len(list_words) == 0:\n",
    "            break\n",
    "        \n",
    "        # each row should have x_len + 1 (both input and target)\n",
    "        for i in range(0,len(list_words)-x_len-1, x_step):\n",
    "            sentences2 = [word for word in list_words[i: i + x_len + 1]]\n",
    "            sentences.append(sentences2)\n",
    "            \n",
    "    return sentences\n",
    "\n",
    "# train_sentences = file_to_sentences(file_train)\n",
    "train_sentences = file_to_sentences(file_train_google)\n",
    "\n",
    "# print('sentences rows = ', len(train_sentences))\n",
    "# print('sentences columns = ', len(train_sentences[0]))\n",
    "# print(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model\n",
    "# window: The maximum distance between the current and predicted word within a sentence\n",
    "# The code below will not account for words in val/test.txt that do not exist in train.txt\n",
    "# Reference: https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "# word_model = gensim.models.Word2Vec(train_sentences, size=100, min_count=1, window=x_len+1, iter=5)\n",
    "# pretrained_weights = word_model.wv.vectors\n",
    "# print(type(pretrained_weights))\n",
    "\n",
    "# def word2idx(word):\n",
    "#     return word_model.wv.vocab[word].index\n",
    "\n",
    "# def idx2word(idx):\n",
    "#     return word_model.wv.index2word[idx]\n",
    "\n",
    "# vocab = google_word_model.wv.vocab\n",
    "# Confirm that word_model works\n",
    "# print(word_model.wv.vocab[\"doubts\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10685, 100)\n",
      "10685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pretrained_weights_mini = []\n",
    "vocab_mini_lst = []\n",
    "vocab_mini_dict = dict()\n",
    "i = 0\n",
    "for word in unique_words_all:\n",
    "    if word in google_word_model.wv.vocab:\n",
    "        i += 1\n",
    "        pretrained_weights_mini.append(pretrained_weights[google_word_model.wv.vocab[word].index][:100])\n",
    "        vocab_mini_lst.append(word)\n",
    "        vocab_mini_dict[word] = i\n",
    "        \n",
    "pretrained_weights_mini = np.array(pretrained_weights_mini)\n",
    "print(pretrained_weights_mini.shape)\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print(len(vocab_mini_lst))\n",
    "\n",
    "def word2idx(word):\n",
    "    return vocab_mini_dict[word]\n",
    "    # The code below works but is too slow when executing sentences_to_2darray\n",
    "    # vocab_mini_lst.index(word)\n",
    "    \n",
    "# def word2idx(word):\n",
    "#     if word in google_word_model.wv.vocab:\n",
    "#         return google_word_model.wv.vocab[word].index\n",
    "#     # Capitalization matters in Google trained word2vec\n",
    "#     # \"united\" is not equal to \"United\"\n",
    "#     elif type(word[0]) == str:\n",
    "#         word = word[0].lower() + word[1:]\n",
    "#         if word in google_word_model.wv.vocab:\n",
    "#             return google_word_model.wv.vocab[word].index\n",
    "#     else:\n",
    "#         return -1\n",
    "def idx2word(idx):\n",
    "    return vocab_mini_lst[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights[1][:200].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'in' in unique_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lling086/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x7fea3b2d9f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_word_model.wv.vocab['To']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#th', 'doughnut', '.', 'grey', 'NASbut', 'DePayne', 'NASand', 'REa', 'and', 'NASWe', 'NASour', 'UCThank', 'copouts', 'travelled', 'SNAbecause', 'nothe', 'Iwhen', 'CASo', ',', 'iuml', 'eacute', 'Tywanza', 'Clementa', 'travelling', 'overspilled', 'NASAnd', 'NASfrom', 'Ritterby', 'Ithe', 'Iyou', '#st'}\n",
      "train_X shape: (79982, 30)\n",
      "train_Y shape: (79982,)\n"
     ]
    }
   ],
   "source": [
    "def sentences_to_2darray(sentences):\n",
    "    \n",
    "    missing_words = set()\n",
    "    \n",
    "    x = np.zeros([len(sentences), x_len], dtype=np.int32)\n",
    "    y = np.zeros([len(sentences)], dtype=np.int32)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, word in enumerate(sentence[:-1]):\n",
    "            if word in vocab:\n",
    "                x[i, t] = word2idx(word)\n",
    "#             elif type(word[0]) == str:\n",
    "#                 word = word[0].lower() + word[1:]\n",
    "#                 if word in vocab:\n",
    "#                     x[i, t] = word2idx(word)\n",
    "            else:\n",
    "                x[i, t] = 0\n",
    "                missing_words.add(word)\n",
    "        if sentence[-1] in vocab:\n",
    "            y[i] = word2idx(sentence[-1])\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    print(missing_words) \n",
    "        \n",
    "    return x, y\n",
    "\n",
    "train_X, train_Y = sentences_to_2darray(train_sentences)\n",
    "print('train_X shape:', train_X.shape)\n",
    "print('train_Y shape:', train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sayyes', 'spires', '#th', 'inventa', 'oughtness', '#D', 'DNAmerica', 'Jobses', 'Vnothing', 'MyRIt', 'whyI', 'PBand', '.', 'MyRA', 'Cultivo', 'ISIeven', 'Estiven', 'IFewer', 'NASand', 'Desiline', 'ISIWe', 'worshippers', 'Borlaugs', 'cuentapropistas', 'CIto', 'Cannot', 'Iwhen', 'NOAand', 'salaamu', 'G#', ',', 'IBstudents', 'iuml', 'tranquillity', 'initiativeto', 'ISIover', 'TPChina', 'inreconcilable', 'BIn', 'ISITake', 'Cachita', 'AIDThat', '#rd', 'pretence', 'UPand', 'futurode', 'Nelba', '#st'}\n",
      "(83044, 30)\n",
      "(83044,)\n"
     ]
    }
   ],
   "source": [
    "# val_X, val_Y = sentences_to_2darray(file_to_sentences(file_val))\n",
    "val_X, val_Y = sentences_to_2darray(file_to_sentences(file_val_google))\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Monitor the GPU memory usage: nvidia-smi\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights_mini]))\n",
    "model.add(LSTM(emdedding_size))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(emdedding_size))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node Adam/Adam/update/ReadVariableOp_6/_26}}]]\n\t [[Func/Adam/gradients/dropout/cond_grad/If/then/_412/input/_1080/_70]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node Adam/Adam/update/ReadVariableOp_6/_26}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_2854]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-794e83eee952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3441\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3442\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3443\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3444\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    560\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    432\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    433\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 434\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node Adam/Adam/update/ReadVariableOp_6/_26}}]]\n\t [[Func/Adam/gradients/dropout/cond_grad/If/then/_412/input/_1080/_70]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node Adam/Adam/update/ReadVariableOp_6/_26}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_2854]"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "WARNING:tensorflow:From /home/lling086/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 294s 4ms/sample - loss: 6.6451 - val_loss: 5.9541\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 285s 4ms/sample - loss: 6.4338 - val_loss: 5.8888\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " . . , that . . , , that . . . , , to , that the , . , . . . . . to . . , the . the , . , . the the , . . , . . . , . , .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " the the . the that . . and s that the the . I that . , not and . to a . to it the those of , the our . you has . to , , , our We from America . of to of , of .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " of legally it groups , have think the to in , force not in since politics office law the economic in a public s absolutely how for to for not even . and of . to is . graduate our have , will rights America her better not the came\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['rocket', 'attacks', 'from', 'Gaza', ',', 'and', 'we', 'have', 'stood', 'up', 'for', 'Israel', 's', 'right', 'to', 'defend', 'itself', '.', 'And', 'that', 'is', 'why', 'Israel', 'has', 'a', 'right', 'to', 'expect', 'Hamas', 'to'] \"\n",
      "\n",
      "rocket attacks from Gaza , and we have stood up for Israel s right to defend itself . And that is why Israel has a right to expect Hamas to\n",
      " from it One tax nation a and dreams dictator do More Right country doing the that to work roads training that forgotten administration , our . costs , them care practical be dynamic offer make . century our does The people of for where out trillions these this pride portion\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3842 - val_loss: 5.8672\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.3252 - val_loss: 5.7456\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " the . of we the the . , , , the the , of . , . the . . . , , the the , . the the of . . to . our that , the the . . . . , . the a . of .\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " us and , , to the to of of a to . that , the the and that . the the is , of the , , , the take . know the , of to the to that of , , as I in . . we , We\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " folks . a Let President long is Golden needs her just with or From forward at Against again taking to immigration today to onto and 98 , to been the . , would change that Iran the Kansas is grace the 100 persuasive acts had willing to neither . it\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['I', 'think', 'that', 'on', 'energy', 'there', 'should', 'be', 'a', 'bipartisan', 'agreement', 'that', 'we', 'have', 'to', 'take', 'a', 'both', 'and', 'approach', 'rather', 'than', 'an', 'either', 'or', 'approach', '.', 'What', 'do', 'I'] \"\n",
      "\n",
      "I think that on energy there should be a bipartisan agreement that we have to take a both and approach rather than an either or approach . What do I\n",
      " Smart us resonated . poison say do the brothers what are discipline than in Forces our 6 , nations And a decide world are trends the discord s 20th let . crisis that After to term two and , was in Qaeda the chamber slows Detroit duty life 1 Bill\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.1820 - val_loss: 5.6788\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 6.0579 - val_loss: 5.5641\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " is the And . the a people . the the of , . the the that . And . the the a . the the the of . the the the the the the the the the the the the . . the the the the the the the our\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " , the And , the And that I a a the economy of the be of and do . the United want in the do and the God of the Americans , . the And . the The States . I . So for our the want . And to\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that just but to But on escape are was class shut family all need and their chance . housing an earth for hospital I families all but at insurance that Air the use , she jobs and insurance have must argument at Yet we with a the destiny who plainly\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['.', 'Imagine', 'imagine', 'for', 'a', 'moment', ',', 'here', 'was', 'a', 'young', 'girl', 'who', 'was', 'just', 'becoming', 'aware', 'of', 'our', 'democracy', 'just', 'beginning', 'to', 'understand', 'the', 'obligations', 'of', 'citizenship', 'just', 'starting'] \"\n",
      "\n",
      ". Imagine imagine for a moment , here was a young girl who was just becoming aware of our democracy just beginning to understand the obligations of citizenship just starting\n",
      " to rebuild actually Scranton their steal while percent to freedom the himself to can stems got could between even makes now proposal cannot push the stop United this to feed flag is economy portion we that I loopholes crisis many made together to patriotism Tom us in things as talking\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 80001 samples, validate on 83061 samples\n",
      "Epoch 1/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 5.9289 - val_loss: 5.5228\n",
      "Epoch 2/2\n",
      "80001/80001 [==============================] - 286s 4ms/sample - loss: 5.7972 - val_loss: 5.4289\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " of the world , , we the a time of the United States . the the States . the , , we the be . the the States . the the time . the the people . the the people . the the a . the the . the the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " that and the economy . We . We , . the as that that the The offering . We have should the sure , the top by the people , this are a church to as we , and our children , have the nation is our the care .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " , . And this to is it but because had you when legally we Because . When was last landscape , . But they there is from sure that should want foreign other roll to continent the values of tomorrow to he know is never have the government of the\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['a', 'sense', 'that', 'if', 'a', 'white', 'male', 'teen', 'was', 'involved', 'in', 'the', 'same', 'kind', 'of', 'scenario', ',', 'that', ',', 'from', 'top', 'to', 'bottom', ',', 'both', 'the', 'outcome', 'and', 'the', 'aftermath'] \"\n",
      "\n",
      "a sense that if a white male teen was involved in the same kind of scenario , that , from top to bottom , both the outcome and the aftermath\n",
      " on . take should and that Bush . setbacks will tonight does and also a deficits of That means war effort once blood from rising came . And by not be quarter it to the anybody ahead to Now you are corporate them built I like going , be essential\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('GoTweights'):\n",
    "    model.load_weights('GoTweights')\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to randomly select a word based on probability distribution\n",
    "#     a = np.log(a) / temperature\n",
    "#     a = np.exp(a) / np.sum(np.exp(a))\n",
    "#     return np.argmax(np.random.multinomial(1, a, 1))\n",
    "    \n",
    "    # Reference: https://github.com/llSourcell/How-to-Generate-Music-Demo/issues/4\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 5):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(train_X, train_Y, batch_size=1280, epochs=2, validation_data=(val_X,val_Y))\n",
    "    model.save_weights('GoTweights',overwrite=True)\n",
    "\n",
    "    # Select a speech from the test file\n",
    "    # randint(a,b) selects from all integers between a and b (inclusive)\n",
    "    # The last speech has zero word, so instead of -1 use -2\n",
    "    gen_speech_index = random.randint(0, len(file_test.split(\"<speech_sep>\"))-2)\n",
    "    # A list of words in the speech\n",
    "    list_words = file_test.split(\"<speech_sep>\")[gen_speech_index].split()\n",
    "    # Select a starting point for the context\n",
    "    start_index = random.randint(0, len(list_words) - x_len - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = list_words[start_index: start_index + x_len]\n",
    "        generated += ' '.join(sentence)\n",
    "        print('----- Generating with seed: \"' , sentence , '\"')\n",
    "        print()\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "\n",
    "        for i in range(50):\n",
    "            x = np.zeros((1, x_len, len(word_train)))\n",
    "            for t, word in enumerate(sentence):\n",
    "                if word in word_train:\n",
    "                    x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "            # model.predict(x, verbose=0).shape = (1, x_len)\n",
    "            # model.predict(x, verbose=0)[0].shape = (x_len, )\n",
    "            preds = model.predict(x, verbose=0)[0]            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "            generated += next_word\n",
    "            del sentence[0]\n",
    "            sentence.append(next_word)\n",
    "            sys.stdout.write(' ')\n",
    "            sys.stdout.write(next_word)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6508,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x, verbose=0)[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266-lstm",
   "language": "python",
   "name": "w266-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
